<!DOCTYPE html><html lang="en"><head><style>
    .utterances {
      position: relative;
      box-sizing: border-box;
      width: 100%;
      max-width: 760px;
      margin-left: auto;
      margin-right: auto;
    }
    .utterances-frame {
      color-scheme: light;
      position: absolute;
      left: 0;
      right: 0;
      width: 1px;
      min-width: 100%;
      max-width: 100%;
      height: 100%;
      border: 0;
    }
  </style><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta http-equiv="Content-Language" content="en"><meta name="color-scheme" content="light dark"><meta name="author" content="Ragnar {Groot Koerkamp}"><meta name="description" content="
Table of Contents

1 Introduction

1.1 Problem statement
1.2 Recommended reading
1.3 Binary search and Eytzinger layout
1.4 Hugepages
1.5 A note on benchmarking
1.6 Cache lines
1.7 S-trees and B-trees


2 Optimizing find

2.1 Linear
2.2 Auto-vectorization
2.3 Trailing zeros
2.4 Popcount
2.5 Manual SIMD


3 Optimizing the search

3.1 Batching
3.2 Prefetching
3.3 Pointer arithmetic

3.3.1 Up-front splat
3.3.2 Byte-based pointers
3.3.3 The final version


3.4 Skip prefetch
3.5 Interleave


4 Optimizing the tree layout

4.1 Left-tree
4.2 Memory layouts
4.3 Node size \(B=15\)

4.3.1 Data structure size


4.4 Summary


5 Prefix partitioning

5.1 Full layout
5.2 Compact subtrees
5.3 The best of both: compact first level
5.4 Overlapping trees
5.5 Human data
5.6 Prefix map
5.7 Summary


6 Multi-threaded comparison
7 Conclusion

7.1 Future work

7.1.1 Branchy search
7.1.2 Interpolation search
7.1.3 Packing data smaller
7.1.4 Returning indices in original data
7.1.5 Range queries







In this post, we will implement a static search tree (S+ tree) for
high-throughput searching of sorted data, as introduced on Algorithmica.
We’ll mostly take the code presented there as a starting point, and optimize it
to its limits. For a large part, I’m simply taking the ‘future work’ ideas of that post
and implementing them. And then there will be a bunch of looking at assembly
code to shave off all the instructions we can.
Lastly, there will be one big addition to optimize throughput: batching."><meta name="keywords" content="blog,developer,phd,computational biology,dna,sequencing,personal,bmi,eth,ethz,eth zurich,pairwise alignment,DP,A*"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Static search trees: 40x faster than binary search"><meta name="twitter:description" content="Table of Contents 1 Introduction 1.1 Problem statement 1.2 Recommended reading 1.3 Binary search and Eytzinger layout 1.4 Hugepages 1.5 A note on benchmarking 1.6 Cache lines 1.7 S-trees and B-trees 2 Optimizing find 2.1 Linear 2.2 Auto-vectorization 2.3 Trailing zeros 2.4 Popcount 2.5 Manual SIMD 3 Optimizing the search 3.1 Batching 3.2 Prefetching 3.3 Pointer arithmetic 3.3.1 Up-front splat 3.3.2 Byte-based pointers 3.3.3 The final version 3.4 Skip prefetch 3.5 Interleave 4 Optimizing the tree layout 4.1 Left-tree 4.2 Memory layouts 4.3 Node size \(B=15\) 4.3.1 Data structure size 4.4 Summary 5 Prefix partitioning 5.1 Full layout 5.2 Compact subtrees 5.3 The best of both: compact first level 5.4 Overlapping trees 5.5 Human data 5.6 Prefix map 5.7 Summary 6 Multi-threaded comparison 7 Conclusion 7.1 Future work 7.1.1 Branchy search 7.1.2 Interpolation search 7.1.3 Packing data smaller 7.1.4 Returning indices in original data 7.1.5 Range queries In this post, we will implement a static search tree (S+ tree) for high-throughput searching of sorted data, as introduced on Algorithmica. We’ll mostly take the code presented there as a starting point, and optimize it to its limits. For a large part, I’m simply taking the ‘future work’ ideas of that post and implementing them. And then there will be a bunch of looking at assembly code to shave off all the instructions we can. Lastly, there will be one big addition to optimize throughput: batching."><meta property="og:url" content="https://curiouscoding.nl/posts/static-search-tree/"><meta property="og:site_name" content="CuriousCoding"><meta property="og:title" content="Static search trees: 40x faster than binary search"><meta property="og:description" content="Table of Contents 1 Introduction 1.1 Problem statement 1.2 Recommended reading 1.3 Binary search and Eytzinger layout 1.4 Hugepages 1.5 A note on benchmarking 1.6 Cache lines 1.7 S-trees and B-trees 2 Optimizing find 2.1 Linear 2.2 Auto-vectorization 2.3 Trailing zeros 2.4 Popcount 2.5 Manual SIMD 3 Optimizing the search 3.1 Batching 3.2 Prefetching 3.3 Pointer arithmetic 3.3.1 Up-front splat 3.3.2 Byte-based pointers 3.3.3 The final version 3.4 Skip prefetch 3.5 Interleave 4 Optimizing the tree layout 4.1 Left-tree 4.2 Memory layouts 4.3 Node size \(B=15\) 4.3.1 Data structure size 4.4 Summary 5 Prefix partitioning 5.1 Full layout 5.2 Compact subtrees 5.3 The best of both: compact first level 5.4 Overlapping trees 5.5 Human data 5.6 Prefix map 5.7 Summary 6 Multi-threaded comparison 7 Conclusion 7.1 Future work 7.1.1 Branchy search 7.1.2 Interpolation search 7.1.3 Packing data smaller 7.1.4 Returning indices in original data 7.1.5 Range queries In this post, we will implement a static search tree (S+ tree) for high-throughput searching of sorted data, as introduced on Algorithmica. We’ll mostly take the code presented there as a starting point, and optimize it to its limits. For a large part, I’m simply taking the ‘future work’ ideas of that post and implementing them. And then there will be a bunch of looking at assembly code to shave off all the instructions we can. Lastly, there will be one big addition to optimize throughput: batching."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-12-18T00:00:00+01:00"><meta property="article:modified_time" content="2024-12-18T00:00:00+01:00"><meta property="article:tag" content="Highlight"><meta property="article:tag" content="Hpc"><meta property="article:tag" content="Search-Index"><title>Static search trees: 40x faster than binary search · CuriousCoding
</title><link rel="canonical" href="https://curiouscoding.nl/posts/static-search-tree/"><link rel="preload" href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as="font" type="font/woff2" crossorigin=""><link rel="stylesheet" href="/css/coder.min.f0251b5f192f0019dbe761fc772de9b49606ffa117c09664b134aa65bbb3696e.css" integrity="sha256-8CUbXxkvABnb52H8dy3ptJYG/6EXwJZksTSqZbuzaW4=" crossorigin="anonymous" media="screen"><link rel="stylesheet" href="/css/style.min.32e59f9cae954616f42bb04d688275834d5036fb36dc8535a1514631f704c112.css" integrity="sha256-MuWfnK6VRhb0K7BNaIJ1g01QNvs23IU1oVFGMfcEwRI=" crossorigin="anonymous" media="screen"><link rel="stylesheet" href="/css/syntax.min.30e277082d77c773cfb8e836c38c0e07aeaf503432344ff0637efa459ad14f6e.css" integrity="sha256-MOJ3CC13x3PPuOg2w4wOB66vUDQyNE/wY376RZrRT24=" crossorigin="anonymous" media="screen"><link rel="icon" type="image/png" href="/images/bike-32.png" sizes="32x32"><link rel="icon" type="image/png" href="/images/bike-64.png" sizes="16x16"><link rel="apple-touch-icon" href="/images/bike-64.png"><link rel="apple-touch-icon" sizes="180x180" href="/images/bike-64.png"><meta name="generator" content="Hugo 0.138.0"><style type="text/css">.CtxtMenu_InfoClose {  top:.2em; right:.2em;}
.CtxtMenu_InfoContent {  overflow:auto; text-align:left; font-size:80%;  padding:.4em .6em; border:1px inset; margin:1em 0px;  max-height:20em; max-width:30em; background-color:#EEEEEE;  white-space:normal;}
.CtxtMenu_Info.CtxtMenu_MousePost {outline:none;}
.CtxtMenu_Info {  position:fixed; left:50%; width:auto; text-align:center;  border:3px outset; padding:1em 2em; background-color:#DDDDDD;  color:black;  cursor:default; font-family:message-box; font-size:120%;  font-style:normal; text-indent:0; text-transform:none;  line-height:normal; letter-spacing:normal; word-spacing:normal;  word-wrap:normal; white-space:nowrap; float:none; z-index:201;  border-radius: 15px;                     /* Opera 10.5 and IE9 */  -webkit-border-radius:15px;               /* Safari and Chrome */  -moz-border-radius:15px;                  /* Firefox */  -khtml-border-radius:15px;                /* Konqueror */  box-shadow:0px 10px 20px #808080;         /* Opera 10.5 and IE9 */  -webkit-box-shadow:0px 10px 20px #808080; /* Safari 3 & Chrome */  -moz-box-shadow:0px 10px 20px #808080;    /* Forefox 3.5 */  -khtml-box-shadow:0px 10px 20px #808080;  /* Konqueror */  filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color="gray", Positive="true"); /* IE */}
</style><style type="text/css">.CtxtMenu_MenuClose {  position:absolute;  cursor:pointer;  display:inline-block;  border:2px solid #AAA;  border-radius:18px;  -webkit-border-radius: 18px;             /* Safari and Chrome */  -moz-border-radius: 18px;                /* Firefox */  -khtml-border-radius: 18px;              /* Konqueror */  font-family: "Courier New", Courier;  font-size:24px;  color:#F0F0F0}
.CtxtMenu_MenuClose span {  display:block; background-color:#AAA; border:1.5px solid;  border-radius:18px;  -webkit-border-radius: 18px;             /* Safari and Chrome */  -moz-border-radius: 18px;                /* Firefox */  -khtml-border-radius: 18px;              /* Konqueror */  line-height:0;  padding:8px 0 6px     /* may need to be browser-specific */}
.CtxtMenu_MenuClose:hover {  color:white!important;  border:2px solid #CCC!important}
.CtxtMenu_MenuClose:hover span {  background-color:#CCC!important}
.CtxtMenu_MenuClose:hover:focus {  outline:none}
</style><style type="text/css">.CtxtMenu_Menu {  position:absolute;  background-color:white;  color:black;  width:auto; padding:5px 0px;  border:1px solid #CCCCCC; margin:0; cursor:default;  font: menu; text-align:left; text-indent:0; text-transform:none;  line-height:normal; letter-spacing:normal; word-spacing:normal;  word-wrap:normal; white-space:nowrap; float:none; z-index:201;  border-radius: 5px;                     /* Opera 10.5 and IE9 */  -webkit-border-radius: 5px;             /* Safari and Chrome */  -moz-border-radius: 5px;                /* Firefox */  -khtml-border-radius: 5px;              /* Konqueror */  box-shadow:0px 10px 20px #808080;         /* Opera 10.5 and IE9 */  -webkit-box-shadow:0px 10px 20px #808080; /* Safari 3 & Chrome */  -moz-box-shadow:0px 10px 20px #808080;    /* Forefox 3.5 */  -khtml-box-shadow:0px 10px 20px #808080;  /* Konqueror */}
.CtxtMenu_MenuItem {  padding: 1px 2em;  background:transparent;}
.CtxtMenu_MenuArrow {  position:absolute; right:.5em; padding-top:.25em; color:#666666;  font-family: null; font-size: .75em}
.CtxtMenu_MenuActive .CtxtMenu_MenuArrow {color:white}
.CtxtMenu_MenuArrow.CtxtMenu_RTL {left:.5em; right:auto}
.CtxtMenu_MenuCheck {  position:absolute; left:.7em;  font-family: null}
.CtxtMenu_MenuCheck.CtxtMenu_RTL { right:.7em; left:auto }
.CtxtMenu_MenuRadioCheck {  position:absolute; left: .7em;}
.CtxtMenu_MenuRadioCheck.CtxtMenu_RTL {  right: .7em; left:auto}
.CtxtMenu_MenuInputBox {  padding-left: 1em; right:.5em; color:#666666;  font-family: null;}
.CtxtMenu_MenuInputBox.CtxtMenu_RTL {  left: .1em;}
.CtxtMenu_MenuComboBox {  left:.1em; padding-bottom:.5em;}
.CtxtMenu_MenuSlider {  left: .1em;}
.CtxtMenu_SliderValue {  position:absolute; right:.1em; padding-top:.25em; color:#333333;  font-size: .75em}
.CtxtMenu_SliderBar {  outline: none; background: #d3d3d3}
.CtxtMenu_MenuLabel {  padding: 1px 2em 3px 1.33em;  font-style:italic}
.CtxtMenu_MenuRule {  border-top: 1px solid #DDDDDD;  margin: 4px 3px;}
.CtxtMenu_MenuDisabled {  color:GrayText}
.CtxtMenu_MenuActive {  background-color: #606872;  color: white;}
.CtxtMenu_MenuDisabled:focus {  background-color: #E8E8E8}
.CtxtMenu_MenuLabel:focus {  background-color: #E8E8E8}
.CtxtMenu_ContextMenu:focus {  outline:none}
.CtxtMenu_ContextMenu .CtxtMenu_MenuItem:focus {  outline:none}
.CtxtMenu_SelectionMenu {  position:relative; float:left;  border-bottom: none; -webkit-box-shadow:none; -webkit-border-radius:0px; }
.CtxtMenu_SelectionItem {  padding-right: 1em;}
.CtxtMenu_Selection {  right: 40%; width:50%; }
.CtxtMenu_SelectionBox {  padding: 0em; max-height:20em; max-width: none;  background-color:#FFFFFF;}
.CtxtMenu_SelectionDivider {  clear: both; border-top: 2px solid #000000;}
.CtxtMenu_Menu .CtxtMenu_MenuClose {  top:-10px; left:-10px}
</style><style id="MJX-CHTML-styles">
mjx-container[jax="CHTML"] {
  line-height: 0;
}

mjx-container [space="1"] {
  margin-left: .111em;
}

mjx-container [space="2"] {
  margin-left: .167em;
}

mjx-container [space="3"] {
  margin-left: .222em;
}

mjx-container [space="4"] {
  margin-left: .278em;
}

mjx-container [space="5"] {
  margin-left: .333em;
}

mjx-container [rspace="1"] {
  margin-right: .111em;
}

mjx-container [rspace="2"] {
  margin-right: .167em;
}

mjx-container [rspace="3"] {
  margin-right: .222em;
}

mjx-container [rspace="4"] {
  margin-right: .278em;
}

mjx-container [rspace="5"] {
  margin-right: .333em;
}

mjx-container [size="s"] {
  font-size: 70.7%;
}

mjx-container [size="ss"] {
  font-size: 50%;
}

mjx-container [size="Tn"] {
  font-size: 60%;
}

mjx-container [size="sm"] {
  font-size: 85%;
}

mjx-container [size="lg"] {
  font-size: 120%;
}

mjx-container [size="Lg"] {
  font-size: 144%;
}

mjx-container [size="LG"] {
  font-size: 173%;
}

mjx-container [size="hg"] {
  font-size: 207%;
}

mjx-container [size="HG"] {
  font-size: 249%;
}

mjx-container [width="full"] {
  width: 100%;
}

mjx-box {
  display: inline-block;
}

mjx-block {
  display: block;
}

mjx-itable {
  display: inline-table;
}

mjx-row {
  display: table-row;
}

mjx-row > * {
  display: table-cell;
}

mjx-mtext {
  display: inline-block;
  text-align: left;
}

mjx-mstyle {
  display: inline-block;
}

mjx-merror {
  display: inline-block;
  color: red;
  background-color: yellow;
}

mjx-mphantom {
  visibility: hidden;
}

_::-webkit-full-page-media, _:future, :root mjx-container {
  will-change: opacity;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-math {
  display: inline-block;
  text-align: left;
  line-height: 0;
  text-indent: 0;
  font-style: normal;
  font-weight: normal;
  font-size: 100%;
  font-size-adjust: none;
  letter-spacing: normal;
  border-collapse: collapse;
  word-wrap: normal;
  word-spacing: normal;
  white-space: nowrap;
  direction: ltr;
  padding: 1px 0;
}

mjx-container[jax="CHTML"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="CHTML"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="CHTML"][display="true"] mjx-math {
  padding: 0;
}

mjx-container[jax="CHTML"][justify="left"] {
  text-align: left;
}

mjx-container[jax="CHTML"][justify="right"] {
  text-align: right;
}

mjx-mi {
  display: inline-block;
  text-align: left;
}

mjx-c {
  display: inline-block;
}

mjx-utext {
  display: inline-block;
  padding: .75em 0 .2em 0;
}

mjx-mo {
  display: inline-block;
  text-align: left;
}

mjx-stretchy-h {
  display: inline-table;
  width: 100%;
}

mjx-stretchy-h > * {
  display: table-cell;
  width: 0;
}

mjx-stretchy-h > * > mjx-c {
  display: inline-block;
  transform: scalex(1.0000001);
}

mjx-stretchy-h > * > mjx-c::before {
  display: inline-block;
  width: initial;
}

mjx-stretchy-h > mjx-ext {
  /* IE */ overflow: hidden;
  /* others */ overflow: clip visible;
  width: 100%;
}

mjx-stretchy-h > mjx-ext > mjx-c::before {
  transform: scalex(500);
}

mjx-stretchy-h > mjx-ext > mjx-c {
  width: 0;
}

mjx-stretchy-h > mjx-beg > mjx-c {
  margin-right: -.1em;
}

mjx-stretchy-h > mjx-end > mjx-c {
  margin-left: -.1em;
}

mjx-stretchy-v {
  display: inline-block;
}

mjx-stretchy-v > * {
  display: block;
}

mjx-stretchy-v > mjx-beg {
  height: 0;
}

mjx-stretchy-v > mjx-end > mjx-c {
  display: block;
}

mjx-stretchy-v > * > mjx-c {
  transform: scaley(1.0000001);
  transform-origin: left center;
  overflow: hidden;
}

mjx-stretchy-v > mjx-ext {
  display: block;
  height: 100%;
  box-sizing: border-box;
  border: 0px solid transparent;
  /* IE */ overflow: hidden;
  /* others */ overflow: visible clip;
}

mjx-stretchy-v > mjx-ext > mjx-c::before {
  width: initial;
  box-sizing: border-box;
}

mjx-stretchy-v > mjx-ext > mjx-c {
  transform: scaleY(500) translateY(.075em);
  overflow: visible;
}

mjx-mark {
  display: inline-block;
  height: 0px;
}

mjx-mn {
  display: inline-block;
  text-align: left;
}

mjx-mfrac {
  display: inline-block;
  text-align: left;
}

mjx-frac {
  display: inline-block;
  vertical-align: 0.17em;
  padding: 0 .22em;
}

mjx-frac[type="d"] {
  vertical-align: .04em;
}

mjx-frac[delims] {
  padding: 0 .1em;
}

mjx-frac[atop] {
  padding: 0 .12em;
}

mjx-frac[atop][delims] {
  padding: 0;
}

mjx-dtable {
  display: inline-table;
  width: 100%;
}

mjx-dtable > * {
  font-size: 2000%;
}

mjx-dbox {
  display: block;
  font-size: 5%;
}

mjx-num {
  display: block;
  text-align: center;
}

mjx-den {
  display: block;
  text-align: center;
}

mjx-mfrac[bevelled] > mjx-num {
  display: inline-block;
}

mjx-mfrac[bevelled] > mjx-den {
  display: inline-block;
}

mjx-den[align="right"], mjx-num[align="right"] {
  text-align: right;
}

mjx-den[align="left"], mjx-num[align="left"] {
  text-align: left;
}

mjx-nstrut {
  display: inline-block;
  height: .054em;
  width: 0;
  vertical-align: -.054em;
}

mjx-nstrut[type="d"] {
  height: .217em;
  vertical-align: -.217em;
}

mjx-dstrut {
  display: inline-block;
  height: .505em;
  width: 0;
}

mjx-dstrut[type="d"] {
  height: .726em;
}

mjx-line {
  display: block;
  box-sizing: border-box;
  min-height: 1px;
  height: .06em;
  border-top: .06em solid;
  margin: .06em -.1em;
  overflow: hidden;
}

mjx-line[type="d"] {
  margin: .18em -.1em;
}

mjx-msup {
  display: inline-block;
  text-align: left;
}

mjx-msub {
  display: inline-block;
  text-align: left;
}

mjx-TeXAtom {
  display: inline-block;
  text-align: left;
}

mjx-munder {
  display: inline-block;
  text-align: left;
}

mjx-over {
  text-align: left;
}

mjx-munder:not([limits="false"]) {
  display: inline-table;
}

mjx-munder > mjx-row {
  text-align: left;
}

mjx-under {
  padding-bottom: .1em;
}

mjx-msqrt {
  display: inline-block;
  text-align: left;
}

mjx-root {
  display: inline-block;
  white-space: nowrap;
}

mjx-surd {
  display: inline-block;
  vertical-align: top;
}

mjx-sqrt {
  display: inline-block;
  padding-top: .07em;
}

mjx-sqrt > mjx-box {
  border-top: .07em solid;
}

mjx-sqrt.mjx-tall > mjx-box {
  padding-left: .3em;
  margin-left: -.3em;
}

mjx-c::before {
  display: block;
  width: 0;
}

.MJX-TEX {
  font-family: MJXZERO, MJXTEX;
}

.TEX-B {
  font-family: MJXZERO, MJXTEX-B;
}

.TEX-I {
  font-family: MJXZERO, MJXTEX-I;
}

.TEX-MI {
  font-family: MJXZERO, MJXTEX-MI;
}

.TEX-BI {
  font-family: MJXZERO, MJXTEX-BI;
}

.TEX-S1 {
  font-family: MJXZERO, MJXTEX-S1;
}

.TEX-S2 {
  font-family: MJXZERO, MJXTEX-S2;
}

.TEX-S3 {
  font-family: MJXZERO, MJXTEX-S3;
}

.TEX-S4 {
  font-family: MJXZERO, MJXTEX-S4;
}

.TEX-A {
  font-family: MJXZERO, MJXTEX-A;
}

.TEX-C {
  font-family: MJXZERO, MJXTEX-C;
}

.TEX-CB {
  font-family: MJXZERO, MJXTEX-CB;
}

.TEX-FR {
  font-family: MJXZERO, MJXTEX-FR;
}

.TEX-FRB {
  font-family: MJXZERO, MJXTEX-FRB;
}

.TEX-SS {
  font-family: MJXZERO, MJXTEX-SS;
}

.TEX-SSB {
  font-family: MJXZERO, MJXTEX-SSB;
}

.TEX-SSI {
  font-family: MJXZERO, MJXTEX-SSI;
}

.TEX-SC {
  font-family: MJXZERO, MJXTEX-SC;
}

.TEX-T {
  font-family: MJXZERO, MJXTEX-T;
}

.TEX-V {
  font-family: MJXZERO, MJXTEX-V;
}

.TEX-VB {
  font-family: MJXZERO, MJXTEX-VB;
}

mjx-stretchy-v mjx-c, mjx-stretchy-h mjx-c {
  font-family: MJXZERO, MJXTEX-S1, MJXTEX-S4, MJXTEX, MJXTEX-A ! important;
}

@font-face /* 0 */ {
  font-family: MJXZERO;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Zero.woff") format("woff");
}

@font-face /* 1 */ {
  font-family: MJXTEX;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Regular.woff") format("woff");
}

@font-face /* 2 */ {
  font-family: MJXTEX-B;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Bold.woff") format("woff");
}

@font-face /* 3 */ {
  font-family: MJXTEX-I;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Math-Italic.woff") format("woff");
}

@font-face /* 4 */ {
  font-family: MJXTEX-MI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Italic.woff") format("woff");
}

@font-face /* 5 */ {
  font-family: MJXTEX-BI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Math-BoldItalic.woff") format("woff");
}

@font-face /* 6 */ {
  font-family: MJXTEX-S1;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size1-Regular.woff") format("woff");
}

@font-face /* 7 */ {
  font-family: MJXTEX-S2;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size2-Regular.woff") format("woff");
}

@font-face /* 8 */ {
  font-family: MJXTEX-S3;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size3-Regular.woff") format("woff");
}

@font-face /* 9 */ {
  font-family: MJXTEX-S4;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size4-Regular.woff") format("woff");
}

@font-face /* 10 */ {
  font-family: MJXTEX-A;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_AMS-Regular.woff") format("woff");
}

@font-face /* 11 */ {
  font-family: MJXTEX-C;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Regular.woff") format("woff");
}

@font-face /* 12 */ {
  font-family: MJXTEX-CB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Bold.woff") format("woff");
}

@font-face /* 13 */ {
  font-family: MJXTEX-FR;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Fraktur-Regular.woff") format("woff");
}

@font-face /* 14 */ {
  font-family: MJXTEX-FRB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Fraktur-Bold.woff") format("woff");
}

@font-face /* 15 */ {
  font-family: MJXTEX-SS;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Regular.woff") format("woff");
}

@font-face /* 16 */ {
  font-family: MJXTEX-SSB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Bold.woff") format("woff");
}

@font-face /* 17 */ {
  font-family: MJXTEX-SSI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Italic.woff") format("woff");
}

@font-face /* 18 */ {
  font-family: MJXTEX-SC;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Script-Regular.woff") format("woff");
}

@font-face /* 19 */ {
  font-family: MJXTEX-T;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Typewriter-Regular.woff") format("woff");
}

@font-face /* 20 */ {
  font-family: MJXTEX-V;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Vector-Regular.woff") format("woff");
}

@font-face /* 21 */ {
  font-family: MJXTEX-VB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Vector-Bold.woff") format("woff");
}

mjx-c.mjx-c1D435.TEX-I::before {
  padding: 0.683em 0.759em 0 0;
  content: "B";
}

mjx-c.mjx-c3D::before {
  padding: 0.583em 0.778em 0.082em 0;
  content: "=";
}

mjx-c.mjx-c31::before {
  padding: 0.666em 0.5em 0 0;
  content: "1";
}

mjx-c.mjx-c35::before {
  padding: 0.666em 0.5em 0.022em 0;
  content: "5";
}

mjx-c.mjx-c1D45B.TEX-I::before {
  padding: 0.442em 0.6em 0.011em 0;
  content: "n";
}

mjx-c.mjx-c1D45E.TEX-I::before {
  padding: 0.442em 0.46em 0.194em 0;
  content: "q";
}

mjx-c.mjx-c34::before {
  padding: 0.677em 0.5em 0 0;
  content: "4";
}

mjx-c.mjx-c33::before {
  padding: 0.665em 0.5em 0.022em 0;
  content: "3";
}

mjx-c.mjx-c38::before {
  padding: 0.666em 0.5em 0.022em 0;
  content: "8";
}

mjx-c.mjx-c2C::before {
  padding: 0.121em 0.278em 0.194em 0;
  content: ",";
}

mjx-c.mjx-c37::before {
  padding: 0.676em 0.5em 0.022em 0;
  content: "7";
}

mjx-c.mjx-c1D456.TEX-I::before {
  padding: 0.661em 0.345em 0.011em 0;
  content: "i";
}

mjx-c.mjx-c32::before {
  padding: 0.666em 0.5em 0 0;
  content: "2";
}

mjx-c.mjx-c2B::before {
  padding: 0.583em 0.778em 0.082em 0;
  content: "+";
}

mjx-c.mjx-c36::before {
  padding: 0.666em 0.5em 0.022em 0;
  content: "6";
}

mjx-c.mjx-c1D43F.TEX-I::before {
  padding: 0.683em 0.681em 0 0;
  content: "L";
}

mjx-c.mjx-c2E::before {
  padding: 0.12em 0.278em 0 0;
  content: ".";
}

mjx-c.mjx-c22C5::before {
  padding: 0.31em 0.278em 0 0;
  content: "\22C5";
}

mjx-c.mjx-c28::before {
  padding: 0.75em 0.389em 0.25em 0;
  content: "(";
}

mjx-c.mjx-c29::before {
  padding: 0.75em 0.389em 0.25em 0;
  content: ")";
}

mjx-c.mjx-c7B::before {
  padding: 0.75em 0.5em 0.25em 0;
  content: "{";
}

mjx-c.mjx-c30::before {
  padding: 0.666em 0.5em 0.022em 0;
  content: "0";
}

mjx-c.mjx-c2026::before {
  padding: 0.12em 1.172em 0 0;
  content: "\2026";
}

mjx-c.mjx-c7D::before {
  padding: 0.75em 0.5em 0.25em 0;
  content: "}";
}

mjx-c.mjx-c1D45C.TEX-I::before {
  padding: 0.441em 0.485em 0.011em 0;
  content: "o";
}

mjx-c.mjx-c2113::before {
  padding: 0.705em 0.417em 0.02em 0;
  content: "\2113";
}

mjx-c.mjx-c1D441.TEX-I::before {
  padding: 0.683em 0.888em 0 0;
  content: "N";
}

mjx-c.mjx-c2265::before {
  padding: 0.636em 0.778em 0.138em 0;
  content: "\2265";
}

mjx-c.mjx-c3C::before {
  padding: 0.54em 0.778em 0.04em 0;
  content: "<";
}

mjx-c.mjx-c1D443.TEX-I::before {
  padding: 0.683em 0.751em 0 0;
  content: "P";
}

mjx-c.mjx-c1D453.TEX-I::before {
  padding: 0.705em 0.55em 0.205em 0;
  content: "f";
}

mjx-c.mjx-c1D465.TEX-I::before {
  padding: 0.442em 0.572em 0.011em 0;
  content: "x";
}

mjx-c.mjx-c1D466.TEX-I::before {
  padding: 0.442em 0.49em 0.205em 0;
  content: "y";
}

mjx-c.mjx-c2F::before {
  padding: 0.75em 0.5em 0.25em 0;
  content: "/";
}

mjx-c.mjx-c5B::before {
  padding: 0.75em 0.278em 0.25em 0;
  content: "[";
}

mjx-c.mjx-c5D::before {
  padding: 0.75em 0.278em 0.25em 0;
  content: "]";
}

mjx-c.mjx-c3E::before {
  padding: 0.54em 0.778em 0.04em 0;
  content: ">";
}

mjx-c.mjx-c39::before {
  padding: 0.666em 0.5em 0.022em 0;
  content: "9";
}

mjx-c.mjx-c25::before {
  padding: 0.75em 0.833em 0.056em 0;
  content: "%";
}

mjx-c.mjx-c22EF::before {
  padding: 0.31em 1.172em 0 0;
  content: "\22EF";
}

mjx-c.mjx-c1D44F.TEX-I::before {
  padding: 0.694em 0.429em 0.011em 0;
  content: "b";
}

mjx-c.mjx-c226B::before {
  padding: 0.567em 1em 0.067em 0;
  content: "\226B";
}

mjx-c.mjx-c6D::before {
  padding: 0.442em 0.833em 0 0;
  content: "m";
}

mjx-c.mjx-c61::before {
  padding: 0.448em 0.5em 0.011em 0;
  content: "a";
}

mjx-c.mjx-c78::before {
  padding: 0.431em 0.528em 0 0;
  content: "x";
}

mjx-c.mjx-c1D446.TEX-I::before {
  padding: 0.705em 0.645em 0.022em 0;
  content: "S";
}

mjx-c.mjx-c1D45D.TEX-I::before {
  padding: 0.442em 0.503em 0.194em 0;
  content: "p";
}

mjx-c.mjx-c1D45A.TEX-I::before {
  padding: 0.442em 0.878em 0.011em 0;
  content: "m";
}

mjx-c.mjx-c1D44E.TEX-I::before {
  padding: 0.441em 0.529em 0.01em 0;
  content: "a";
}

mjx-c.mjx-c2264::before {
  padding: 0.636em 0.778em 0.138em 0;
  content: "\2264";
}

mjx-c.mjx-c1D463.TEX-I::before {
  padding: 0.443em 0.485em 0.011em 0;
  content: "v";
}

mjx-c.mjx-c2212::before {
  padding: 0.583em 0.778em 0.082em 0;
  content: "\2212";
}

mjx-c.mjx-c221A::before {
  padding: 0.8em 0.853em 0.2em 0;
  content: "\221A";
}

mjx-c.mjx-c1D458.TEX-I::before {
  padding: 0.694em 0.521em 0.011em 0;
  content: "k";
}

mjx-c.mjx-c1D442.TEX-I::before {
  padding: 0.704em 0.763em 0.022em 0;
  content: "O";
}

mjx-c.mjx-c6C::before {
  padding: 0.694em 0.278em 0 0;
  content: "l";
}

mjx-c.mjx-c67::before {
  padding: 0.453em 0.5em 0.206em 0;
  content: "g";
}

mjx-c.mjx-c2061::before {
  padding: 0 0 0 0;
  content: "";
}
</style></head><body class="colorscheme-light"><main class="wrapper"><nav class="navigation"><section class="container"><a class="navigation-title" href="/">CuriousCoding
</a><input type="checkbox" id="menu-toggle">
<label class="menu-button float-right" for="menu-toggle"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></label><ul class="navigation-list"><li class="navigation-item"><a class="navigation-link" href="/posts/">All posts</a></li><li class="navigation-item"><a class="navigation-link" href="/pages/projects">Projects</a></li><li class="navigation-item"><a class="navigation-link" href="/pages/publications">Publications &amp; Talks</a></li><li class="navigation-item"><a class="navigation-link" href="/pages/about/">About</a></li></ul></section></nav><div class="content"><section class="container post"><article><header><div class="post-title"><h1 class="title"><a class="title-link" href="https://curiouscoding.nl/posts/static-search-tree/">Static search trees: 40x faster than binary search</a></h1></div><div class="post-meta"><div class="date"><span class="posted-on" title="created"><i class="fa fa-calendar" aria-hidden="true"></i>
<time datetime="2024-12-18T00:00:00+01:00">December 2024
</time></span><span class="reading-time"><i class="fa fa-clock-o" aria-hidden="true"></i>
60-minute read</span></div><div class="authors"><i class="fa fa-user" aria-hidden="true"></i>
<a href="/authors/ragnar-groot-koerkamp/">Ragnar Groot Koerkamp</a></div><div class="tags"><i class="fa fa-tag" aria-hidden="true"></i>
<span class="tag category" data-tag="results"><a href="/categories/results/">results</a></span>
<span class="tag category" data-tag="walkthrough"><a href="/categories/walkthrough/">walkthrough</a></span>
<span class="tag" data-tag="highlight"><a href="/tags/highlight/">highlight</a></span>
<span class="tag" data-tag="hpc"><a href="/tags/hpc/">hpc</a></span>
<span class="tag" data-tag="search-index"><a href="/tags/search-index/">search-index</a></span></div></div></header><div><div class="ox-hugo-toc toc has-section-numbers"><div class="heading">Table of Contents</div><ul><li class="selected parent"><span class="section-num">1</span> <a href="#introduction">Introduction</a><ul><li class="selected parent"><span class="section-num">1.1</span> <a href="#problem-statement">Problem statement</a></li><li><span class="section-num">1.2</span> <a href="#recommended-reading">Recommended reading</a></li><li><span class="section-num">1.3</span> <a href="#binary-search-and-eytzinger-layout">Binary search and Eytzinger layout</a></li><li><span class="section-num">1.4</span> <a href="#hugepages">Hugepages</a></li><li><span class="section-num">1.5</span> <a href="#a-note-on-benchmarking">A note on benchmarking</a></li><li><span class="section-num">1.6</span> <a href="#cache-lines">Cache lines</a></li><li><span class="section-num">1.7</span> <a href="#s-trees-and-b-trees">S-trees and B-trees</a></li></ul></li><li><span class="section-num">2</span> <a href="#optimizing-find">Optimizing <code>find</code></a><ul><li><span class="section-num">2.1</span> <a href="#linear">Linear</a></li><li><span class="section-num">2.2</span> <a href="#auto-vectorization">Auto-vectorization</a></li><li><span class="section-num">2.3</span> <a href="#trailing-zeros">Trailing zeros</a></li><li><span class="section-num">2.4</span> <a href="#popcount">Popcount</a></li><li><span class="section-num">2.5</span> <a href="#manual-simd">Manual SIMD</a></li></ul></li><li><span class="section-num">3</span> <a href="#optimizing-the-search">Optimizing the search</a><ul><li><span class="section-num">3.1</span> <a href="#batching">Batching</a></li><li><span class="section-num">3.2</span> <a href="#prefetching">Prefetching</a></li><li><span class="section-num">3.3</span> <a href="#pointer-arithmetic">Pointer arithmetic</a><ul><li><span class="section-num">3.3.1</span> <a href="#up-front-splat">Up-front splat</a></li><li><span class="section-num">3.3.2</span> <a href="#byte-based-pointers">Byte-based pointers</a></li><li><span class="section-num">3.3.3</span> <a href="#the-final-version">The final version</a></li></ul></li><li><span class="section-num">3.4</span> <a href="#skip-prefetch">Skip prefetch</a></li><li><span class="section-num">3.5</span> <a href="#interleave">Interleave</a></li></ul></li><li><span class="section-num">4</span> <a href="#optimizing-the-tree-layout">Optimizing the tree layout</a><ul><li><span class="section-num">4.1</span> <a href="#left-tree">Left-tree</a></li><li><span class="section-num">4.2</span> <a href="#memory-layouts">Memory layouts</a></li><li><span class="section-num">4.3</span> <a href="#node-size-b-15">Node size <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi><mo>=</mo><mn>15</mn></math></mjx-assistive-mml></mjx-container></a><ul><li><span class="section-num">4.3.1</span> <a href="#data-structure-size">Data structure size</a></li></ul></li><li><span class="section-num">4.4</span> <a href="#summary">Summary</a></li></ul></li><li><span class="section-num">5</span> <a href="#prefix-partitioning">Prefix partitioning</a><ul><li><span class="section-num">5.1</span> <a href="#full-layout">Full layout</a></li><li><span class="section-num">5.2</span> <a href="#compact-subtrees">Compact subtrees</a></li><li><span class="section-num">5.3</span> <a href="#the-best-of-both-compact-first-level">The best of both: compact first level</a></li><li><span class="section-num">5.4</span> <a href="#overlapping-trees">Overlapping trees</a></li><li><span class="section-num">5.5</span> <a href="#human-data">Human data</a></li><li><span class="section-num">5.6</span> <a href="#prefix-map">Prefix map</a></li><li><span class="section-num">5.7</span> <a href="#prefix-summary">Summary</a></li></ul></li><li><span class="section-num">6</span> <a href="#multi-threaded-comparison">Multi-threaded comparison</a></li><li><span class="section-num">7</span> <a href="#conclusion">Conclusion</a><ul><li><span class="section-num">7.1</span> <a href="#future-work">Future work</a><ul><li><span class="section-num">7.1.1</span> <a href="#branchy-search">Branchy search</a></li><li><span class="section-num">7.1.2</span> <a href="#interpolation-search">Interpolation search</a></li><li><span class="section-num">7.1.3</span> <a href="#packing-data-smaller">Packing data smaller</a></li><li><span class="section-num">7.1.4</span> <a href="#returning-indices-in-original-data">Returning indices in original data</a></li><li><span class="section-num">7.1.5</span> <a href="#range-queries">Range queries</a></li></ul></li></ul></li></ul></div><p>In this post, we will implement a static search tree (S+ tree) for
high-throughput searching of sorted data, as <a href="https://en.algorithmica.org/hpc/data-structures/s-tree/">introduced</a> on Algorithmica.
We’ll mostly take the code presented there as a starting point, and optimize it
to its limits. For a large part, I’m simply taking the ‘future work’ ideas of that post
and implementing them. And then there will be a bunch of looking at assembly
code to shave off all the instructions we can.
Lastly, there will be one big addition to optimize throughput: <em>batching</em>.</p><p>All <strong>source code</strong>, including benchmarks and plotting code, is at <a href="https://github.com/RagnarGrootKoerkamp/suffix-array-searching/tree/master/static-search-tree">github:RagnarGrootKoerkamp/suffix-array-searching</a>.</p><h1 id="introduction"><span class="section-num">1</span> Introduction
<a class="heading-link" href="#introduction"><i class="fa fa-link" aria-hidden="true"></i></a></h1><h2 id="problem-statement"><span class="section-num">1.1</span> Problem statement
<a class="heading-link" href="#problem-statement"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p><strong>Input.</strong> A sorted list of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="1" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></mjx-assistive-mml></mjx-container> 32bit unsigned integers <code>vals: Vec&lt;u32&gt;</code>.</p><p><strong>Output.</strong> A data structure that supports queries <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></mjx-assistive-mml></mjx-container>, returning the smallest
element of <code>vals</code> that is at least <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="3" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></mjx-assistive-mml></mjx-container>, or <code>u32::MAX</code> if no such element exists.
Optionally, the index of this element may also be returned.</p><p><strong>Metric.</strong> We optimize <em>throughput</em>. That is, the number of (independent) queries
that can be answered per second. The typical case is where we have a
sufficiently long <code>queries: &amp;[u32]</code> as input, and return a corresponding <code>answers: Vec&lt;u32&gt;</code>.</p><p>Note that we’ll usually report reciprocal throughput as <code>ns/query</code> (or just
<code>ns</code>), instead of <code>queries/s</code>. You can think of this as amortized (not <em>average</em>) time spent per query.</p><p><strong>Benchmarking setup.</strong> For now, we will assume that both the input and queries
are simply uniform random sampled 31bit integers<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a><span class="fn-tooltip"><span class="fn-number">1</span><span class="fn-text"><p>You’ll see later why not 32bit&nbsp;</p></span></span></sup>.</p><p><strong>Code.</strong>
In code, this can be modelled by the trait shown in <a href="#code-snippet--trait">Code Snippet 1</a>.</p><p><a id="code-snippet--trait"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-rust" data-lang="rust"><span class="line"><span class="cl"><span class="k">trait</span><span class="w"> </span><span class="n">SearchIndex</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="sd">/// Two functions with default implementations in terms of each other.
</span></span></span><span class="line"><span class="cl"><span class="sd"></span><span class="w">    </span><span class="k">fn</span> <span class="nf">query_one</span><span class="p">(</span><span class="o">&amp;</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">query</span>: <span class="kt">u32</span><span class="p">)</span><span class="w"> </span>-&gt; <span class="kt">u32</span> <span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="bp">Self</span>::<span class="n">query</span><span class="p">(</span><span class="o">&amp;</span><span class="fm">vec!</span><span class="p">[</span><span class="n">query</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">fn</span> <span class="nf">query</span><span class="p">(</span><span class="o">&amp;</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">queries</span>: <span class="kp">&amp;</span><span class="p">[</span><span class="kt">u32</span><span class="p">])</span><span class="w"> </span>-&gt; <span class="nb">Vec</span><span class="o">&lt;</span><span class="kt">u32</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">queries</span><span class="p">.</span><span class="n">iter</span><span class="p">().</span><span class="n">map</span><span class="p">(</span><span class="o">|&amp;</span><span class="n">q</span><span class="o">|</span><span class="w"> </span><span class="bp">Self</span>::<span class="n">query_one</span><span class="p">(</span><span class="n">q</span><span class="p">)).</span><span class="n">collect</span><span class="p">()</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--trait">Code Snippet 1</a>:</span>
Trait that our solution should implement.</div><h2 id="recommended-reading"><span class="section-num">1.2</span> Recommended reading
<a class="heading-link" href="#recommended-reading"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>The classical solution to this problem is <strong>binary search</strong>, which we will briefly
visit in the next section. A great paper on this and other search layouts is
<a href="#citeproc_bib_item_2">“Array Layouts for Comparison-Based Searching”</a> by Khuong and Morin (<a href="#citeproc_bib_item_2">2017</a>).
Algorithmica also has a <a href="https://en.algorithmica.org/hpc/data-structures/binary-search/">case study</a> based on that paper.</p><p>This post will focus on <strong>S+ trees</strong>, as introduced on Algorithmica in the
followup post, <a href="https://en.algorithmica.org/hpc/data-structures/s-tree/">static B-trees</a>. In the interest of my time, I will mostly assume
that you are familiar with that post.</p><p>I also recommend reading my work-in-progress <a href="../cpu-benchmarks">introduction to CPU performance</a>,
which contains some benchmarks pushing the CPU to its limits. We will use the
metrics obtained there as baseline to understand our optimization attempts.</p><p>Also helpful is the <a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#=undefined&amp;techs=AVX_ALL">Intel Intrinsics Guide</a> when looking into SIMD instructions.
Note that we’ll only be using <code>AVX2</code> instructions here, as in, we’re assuming
intel. And we’re not assuming less available <code>AVX512</code> instructions (in
particular, since my laptop doesn’t have them).</p><h2 id="binary-search-and-eytzinger-layout"><span class="section-num">1.3</span> Binary search and Eytzinger layout
<a class="heading-link" href="#binary-search-and-eytzinger-layout"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>As a baseline, we will use the Rust standard library binary search implementation.</p><p><a id="code-snippet--binary-search"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-rust" data-lang="rust"><span class="line"><span class="cl"><span class="k">pub</span><span class="w"> </span><span class="k">struct</span> <span class="nc">SortedVec</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">vals</span>: <span class="nb">Vec</span><span class="o">&lt;</span><span class="kt">u32</span><span class="o">&gt;</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">impl</span><span class="w"> </span><span class="n">SortedVec</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">pub</span><span class="w"> </span><span class="k">fn</span> <span class="nf">binary_search_std</span><span class="p">(</span><span class="o">&amp;</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">q</span>: <span class="kt">u32</span><span class="p">)</span><span class="w"> </span>-&gt; <span class="kt">u32</span> <span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">vals</span><span class="p">.</span><span class="n">binary_search</span><span class="p">(</span><span class="o">&amp;</span><span class="n">q</span><span class="p">).</span><span class="n">unwrap_or_else</span><span class="p">(</span><span class="o">|</span><span class="n">i</span><span class="o">|</span><span class="w"> </span><span class="n">i</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="bp">self</span><span class="p">.</span><span class="n">vals</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--binary-search">Code Snippet 2</a>:</span>
The binary search in the Rust standard library.</div><p>The main conclusion of the array layouts paper (<a href="#citeproc_bib_item_2">Khuong and Morin 2017</a>) is
that the Eytzinger layout is one of the best in practice.
This layout reorders the values in memory: the binary search effectively is a
binary search tree on the data, the root the middle node, then the nodes at
positions <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="4" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mn>1</mn><mn>4</mn></mfrac><mi>n</mi></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="5" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c33"></mjx-c></mjx-mn></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mn>3</mn><mn>4</mn></mfrac><mi>n</mi></math></mjx-assistive-mml></mjx-container>, then <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="6" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mfrac space="2"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c33"></mjx-c></mjx-mn></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mfrac space="2"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mfrac space="2"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c37"></mjx-c></mjx-mn></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mn>1</mn><mn>8</mn></mfrac><mi>n</mi><mo>,</mo><mfrac><mn>3</mn><mn>8</mn></mfrac><mi>n</mi><mo>,</mo><mfrac><mn>5</mn><mn>8</mn></mfrac><mi>n</mi><mo>,</mo><mfrac><mn>7</mn><mn>8</mn></mfrac><mi>n</mi></math></mjx-assistive-mml></mjx-container>, and so on. The main benefit of this layout is that all values needed
for the first steps of the binary search are close together, so they can be
cached efficiently. If we put the root at index <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="7" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn></math></mjx-assistive-mml></mjx-container>, the two children of the
node at index <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="8" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi></math></mjx-assistive-mml></mjx-container> are at <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="9" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>2</mn><mi>i</mi></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn></math></mjx-assistive-mml></mjx-container>. This means that we can effectively
prefetch the next cache line, before knowing whether we need index <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="11" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>2</mn><mi>i</mi></math></mjx-assistive-mml></mjx-container> or
<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="12" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn></math></mjx-assistive-mml></mjx-container>. This can be taken a step further and we can prefetch the cache line
containing indices <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="13" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>16</mn><mi>i</mi></math></mjx-assistive-mml></mjx-container> to <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="14" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>16</mn><mi>i</mi><mo>+</mo><mn>15</mn></math></mjx-assistive-mml></mjx-container>, which are exactly the values needed 4
iterations from now.
For a large part, this can quite effectively hide the latency associated with
the traversal of the tree.</p><p><a id="code-snippet--eytzinger"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-rust" data-lang="rust"><span class="line"><span class="cl"><span class="k">pub</span><span class="w"> </span><span class="k">struct</span> <span class="nc">Eytzinger</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="sd">/// The root of the tree is at index 1.
</span></span></span><span class="line"><span class="cl"><span class="sd"></span><span class="w">    </span><span class="n">vals</span>: <span class="nb">Vec</span><span class="o">&lt;</span><span class="kt">u32</span><span class="o">&gt;</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">impl</span><span class="w"> </span><span class="n">Eytzinger</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="sd">/// L: number of levels ahead to prefetch.
</span></span></span><span class="line"><span class="cl"><span class="sd"></span><span class="w">    </span><span class="k">pub</span><span class="w"> </span><span class="k">fn</span> <span class="nf">search_prefetch</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="n">L</span>: <span class="kt">usize</span><span class="o">&gt;</span><span class="p">(</span><span class="o">&amp;</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">q</span>: <span class="kt">u32</span><span class="p">)</span><span class="w"> </span>-&gt; <span class="kt">u32</span> <span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="k">mut</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">L</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">vals</span><span class="p">.</span><span class="n">len</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">q</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="kt">usize</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="n">prefetch_index</span><span class="p">(</span><span class="o">&amp;</span><span class="bp">self</span><span class="p">.</span><span class="n">vals</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">L</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">idx</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c1">// The last few iterations don't need prefetching anymore.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">        </span><span class="k">while</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">vals</span><span class="p">.</span><span class="n">len</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">q</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="kt">usize</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">zeros</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">idx</span><span class="p">.</span><span class="n">trailing_ones</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">zeros</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="bp">self</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--eytzinger">Code Snippet 3</a>:</span>
Implementation of searching the Eytzinger layout, with <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="15" style="font-size: 119.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>L</mi><mo>=</mo><mn>4</mn></math></mjx-assistive-mml></mjx-container> levels of prefetching.</div><p>If we plot these two, we see that Eytzinger layout performs as good as binary
search when the array fits in L2 cache (<code>256kB</code> for me, the middle red line), but starts to be much
better than binary search as the array grows to be much larger than the L3 cache (<code>12MB</code>).
In the end, Eytzinger search is around 4 times faster, which nicely corresponds
to being able to prefetch 4 iterations of cache lines from memory at a time.</p><figure class="inset large"><a href="/ox-hugo/1-binary-search.svg"><img src="/ox-hugo/1-binary-search.svg" alt="Figure 1: Query throughput of binary search and Eytzinger layout as the size of the input increases. At 1GB input, binary search needs around 1150ns/query, while Eytzinger is 6x faster at 200ns/query."></a><figcaption><p><span class="figure-number">Figure 1: </span>Query throughput of binary search and Eytzinger layout as the size of the input increases. At <code>1GB</code> input, binary search needs around <code>1150ns/query</code>, while Eytzinger is 6x faster at <code>200ns/query</code>.</p></figcaption></figure><h2 id="hugepages"><span class="section-num">1.4</span> Hugepages
<a class="heading-link" href="#hugepages"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>For all experiments, we’ll make sure to allocate the tree using <code>2MB</code> <em>hugepages</em>
by default, instead of the usual <code>4kB</code> pages.
This reduces pressure on the <em>translation lookaside buffer</em> (TLB) that
translates virtual memory addresses to hardware memory addresses, since its
internal table of pages is much smaller when using hugepages, and hence can be
cached better.</p><p>With <em>transparent hugepages</em> enabled, they are automatically given out whenever
allocating an exact multiple of <code>2MB</code>, and so we always round up the allocation
for the tree to the next multiple of <code>2MB</code>. However, it turns out that small
allocations below <code>32MB</code> still go on the program’s <em>heap</em>, rather than asking
the kernel for new memory pages, causing them to not actually be hugepages.
Thus, all allocations we do are actually rounded up to the next multiple of
<code>32MB</code> instead.</p><p>All together, hugepages sometimes makes a small difference when the dataset is
indeed between <code>1MB</code> and <code>32MB</code> in size. Smaller data structures don’t really need
hugepages anyway. Enabling them for the Eytzinger layout as in the plot above
also gives a significant speedup for larger sizes.</p><h2 id="a-note-on-benchmarking"><span class="section-num">1.5</span> A note on benchmarking
<a class="heading-link" href="#a-note-on-benchmarking"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>The plots have the size of the input data on the logarithmic (bottom) x-axis. On the top,
they show the corresponding number of elements in the vector, which is 4 times
less, since each element is a <code>u32</code> spanning 4 bytes.
Measurements are taken at values <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="16" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.363em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mi>i</mi></msup></math></mjx-assistive-mml></mjx-container>, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="17" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msup space="3"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.363em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1.25</mn><mo>⋅</mo><msup><mn>2</mn><mi>i</mi></msup></math></mjx-assistive-mml></mjx-container>, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="18" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msup space="3"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.363em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1.5</mn><mo>⋅</mo><msup><mn>2</mn><mi>i</mi></msup></math></mjx-assistive-mml></mjx-container>, and
<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="19" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c37"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msup space="3"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.363em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1.75</mn><mo>⋅</mo><msup><mn>2</mn><mi>i</mi></msup></math></mjx-assistive-mml></mjx-container>.</p><p>The y-axis shows measured time per query. In the plot above, it says
<em>latency</em>, since it is benchmarked as <code>for q in queries { index.query(q); }</code>.
Even then, the pipelining and out-of-order execution of the CPU will make it
execute multiple iterations in parallel. Specifically, while it is waiting for
the last cache lines of iteration <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="20" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi></math></mjx-assistive-mml></mjx-container>, it can already start executing the first
instructions of the next query. To measure the true latency, we would have to
introduce a <em>loop carried dependency</em> by making query <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="21" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi><mo>+</mo><mn>1</mn></math></mjx-assistive-mml></mjx-container> dependent on the
result of query <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="22" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi></math></mjx-assistive-mml></mjx-container>.
However, the main goal of this post is to optimize for <em>throughput</em>, so we won’t
bother with that.</p><p>Thus, all plots will show the throughput of doing <code>index.query(all_queries)</code>.</p><p>For the benchmarks, I’m using my laptop’s <code>i7-10750H</code> CPU, with the frequency
fixed to <code>2.6GHz</code> using <a href="#code-snippet--pin">Code Snippet 4</a>.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a><span class="fn-tooltip"><span class="fn-number">2</span><span class="fn-text"><p>One might argue that this is unrealistic since
in practice processors <em>do</em> have dynamic frequencies, but here I prefer reproducible
benchmarks over realistic benchmarks.&nbsp;</p></span></span></sup></p><p><a id="code-snippet--pin"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo cpupower frequency-set -g powersave -d 2.6GHz -u 2.6GHz
</span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--pin">Code Snippet 4</a>:</span>
Pinning the CPU frequency to <code>2.6GHz</code>.</div><p>Also relevant are the sizes of the caches: <code>32KiB</code> L1 cache per core, <code>256KiB</code>
L2 cache per core, and <code>12MiB</code> L3 cache shared between the physical 6 cores.
Furthermore, hyper-threading is disabled.</p><p>All measurements are done 5 times. The line follows the median, and we show the
spread of the 2nd to 4th value (i.e., after discarding the minimum and maximum).
Observe that in most of the plot above, the spread is barely visible! Thus,
while especially the graph for binary search looks very noisy, that ’noise’ is
in fact completely reproducible. Indeed, it’s caused by effects of <em>cache
associativity</em>, as explained in the array layouts paper
(Khuong and Morin (<a href="#citeproc_bib_item_2">2017</a>); this post is long enough already).</p><h2 id="cache-lines"><span class="section-num">1.6</span> Cache lines
<a class="heading-link" href="#cache-lines"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>Main memory and the caches work at the level of <em>cache lines</em> consisting of 64
bytes (at least on my machine), or 16 <code>u32</code> values. Thus, even if you only read a single byte, if
the cache line containing that byte is not yet in the L1 cache, the entire thing
will be fetched from RAM or L3 or L2 into L1.</p><p>Plain binary search typically only uses a single value of each cache line,
until it gets to the end of the search where the last 16 values span just 1 or 2
cache lines.</p><p>They Eytzinger layout suffers the same problem: even though the next cache line
can be prefetched, it still only uses a single value in each.
This fundamentally means that both these search schemes are using the available
memory bandwidth quite inefficiently, and since most of what they are doing is
waiting for memory to come through, that’s not great.
Also, while that’s not relevant <em>yet</em>, when doing this with many threads in
parallel, or with batching, single-core RAM throughput and the throughput of the
main memory itself become a bottleneck.</p><p>It would be much better if <em>somehow</em>, we could use the information in each cache
line much more efficiently ;)</p><p>We can do that by storing our data in a different way. Instead of storing it
layer by layer, so that each iteration goes into a new layer,
we can store 4 layers of the tree at a time (<a href="#code-snippet--node">Code Snippet 5</a>). That takes 15 values, and could
nicely be padded into a full cache line. Then when we fetch a cache line, we can
use it for 4 iterations at once – much better!
On the other hand, now we can’t prefetch upcoming cache lines in advance
anymore, so that overall the latency will be the same. But we fetch up to 4
times fewer cache lines overall, which should help throughput.</p><p>Unfortunately, I don’t have code and plots here, because what I really want to
focus on is the next bit.</p><p><a id="figure--node"></a></p><figure class="inset large"><a href="/ox-hugo/packed-eytzinger.svg"><img src="/ox-hugo/packed-eytzinger.svg" alt="Figure 2: The first two rows show how we could pack four layers of the Eytzinger search into a single cache line. The first follows a classic binary search layout, while the second applies the Eytzinger layout recursively. The third row shows an S-tree node instead. For simplicity and clarity, I’m using consecutive values, but in practice, this would be any list of sorted numbers."></a><figcaption><p><span class="figure-number">Figure 2: </span>The first two rows show how we could pack four layers of the Eytzinger search into a single cache line. The first follows a classic binary search layout, while the second applies the Eytzinger layout recursively. The third row shows an S-tree node instead. For simplicity and clarity, I’m using consecutive values, but in practice, this would be any list of sorted numbers.</p></figcaption></figure><h2 id="s-trees-and-b-trees"><span class="section-num">1.7</span> S-trees and B-trees
<a class="heading-link" href="#s-trees-and-b-trees"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>We just ended with a <em>node</em> of 15 values that represent a height-4 search tree
in which we can binary search. From there, it’s just a small step to S-trees.</p><p><strong>B-trees.</strong> But first I have to briefly mention B-trees though (<a href="https://en.wikipedia.org/wiki/B-tree">wikipedia</a>). Those are
the more classic dynamic variant, where nodes are linked together via pointers.
As wikipedia writes, they are typically used with much larger block sizes, for
example 4kB, since files read from disk usually come in 4kB chunks. Thus, they
also have much larger branching factors.</p><p><strong>S-trees.</strong> But we will instead use S-trees, as named so by Algorithmica. They
are a nice middle ground between the high branching factor of B-trees, and the
compactness of the Eytzinger layout.
Instead of interpreting the 15 values as a search tree, we can also store them
in a sorted way, and consider them as a 16-ary search tree: the 15 values simply
split the data in the subtree into 16 parts, and we can do a linear scan to find
which part to recurse into.
But if we store 15 values and one padding in a cache line, we might as well make
it 16 values and have a branching factor of 17 instead.</p><p><strong>S+ trees.</strong> B-trees and S-trees only store each value once, either in a leaf node or
in an internal node. This turns out to be somewhat annoying, since we must track
in which layer the result was found. To simplify this, we can store <em>all</em> values
as a leaf, and <em>duplicate</em> them in the internal nodes. This is then called a B+
tree or S+ tree. However, I will be lazy and just use S-tree to include this modification.</p><p><a id="figure--stree-full"></a></p><figure class="inset large"><a href="/ox-hugo/full.svg"><img src="/ox-hugo/full.svg" alt="Figure 3: An example of a ‘full’ S+ tree (that I will from now just call S-tree) on 18 values with nodes of size (B=2) and branching factor (B+1=3). Each internal node stores the smallest value in the subtree on its right. In memory, the layers are simply packed together behind each other."></a><figcaption><p><span class="figure-number">Figure 3: </span>An example of a ‘full’ S+ tree (that I will from now just call S-tree) on 18 values with nodes of size (B=2) and branching factor (B+1=3). Each internal node stores the smallest value in the subtree on its right. In memory, the layers are simply packed together behind each other.</p></figcaption></figure><p>A full S-tree can be navigated in a way similar to the Eytzinger layout: The
node (note: not<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a><span class="fn-tooltip"><span class="fn-number">3</span><span class="fn-text"><p>;)&nbsp;</p></span></span></sup> value) at index <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="23" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi></math></mjx-assistive-mml></mjx-container> has its <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="24" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi><mo>+</mo><mn>1</mn></math></mjx-assistive-mml></mjx-container> child-nodes at indices <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="25" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2026"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mi>B</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>⋅</mo><mi>i</mi><mo>+</mo><mn>1</mn><mo>+</mo><mo fence="false" stretchy="false">{</mo><mn>0</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>B</mi><mo fence="false" stretchy="false">}</mo></math></mjx-assistive-mml></mjx-container>.</p><p>When the tree is only partially filled, the full layout can waste a lot of space
(<a href="#figure--stree-partial">Figure 4</a>). Instead, we can <em>pack</em> the layers together, by storing the
offset <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="26" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45C TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>o</mi><mi>ℓ</mi></msub></math></mjx-assistive-mml></mjx-container> of each layer.</p><p>The children of node <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="27" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45C TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>o</mi><mi>ℓ</mi></msub><mo>+</mo><mi>i</mi></math></mjx-assistive-mml></mjx-container> are then at <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="28" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45C TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2026"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>o</mi><mrow data-mjx-texclass="ORD"><mi>ℓ</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>+</mo><mo stretchy="false">(</mo><mi>B</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>⋅</mo><mi>i</mi><mo>+</mo><mo fence="false" stretchy="false">{</mo><mn>0</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>B</mi><mo fence="false" stretchy="false">}</mo></math></mjx-assistive-mml></mjx-container>.</p><p><a id="figure--stree-partial"></a></p><figure class="inset large"><a href="/ox-hugo/partial.svg"><img src="/ox-hugo/partial.svg" alt="Figure 4: The full representation can be inefficient. The packed representation removes the empty space, and explicitly stores the offset (o_ell) where each layer starts."></a><figcaption><p><span class="figure-number">Figure 4: </span>The <em>full</em> representation can be inefficient. The <em>packed</em> representation removes the empty space, and explicitly stores the offset (o_ell) where each layer starts.</p></figcaption></figure><p>At last, let’s have a look at some code. Each node in the tree is simply
represented as a list of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="29" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>N</mi><mo>=</mo><mn>16</mn></math></mjx-assistive-mml></mjx-container> <code>u32</code> values. We explicitly ask that nodes are
aligned to 64byte cache line boundaries.</p><p><a id="code-snippet--node"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-rust" data-lang="rust"><span class="line"><span class="cl"><span class="cp">#[repr(align(64))]</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">pub</span><span class="w"> </span><span class="k">struct</span> <span class="nc">TreeNode</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="n">N</span>: <span class="kt">usize</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">data</span>: <span class="p">[</span><span class="kt">u32</span><span class="p">;</span><span class="w"> </span><span class="n">N</span><span class="p">],</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--node">Code Snippet 5</a>:</span>
Search tree node, aligned to a 64 byte cache line. For now, N is always 16. The values in a node must always be sorted.</div><p>The S-tree itself is simply a list of nodes, and the offsets where each layer starts.</p><p><a id="code-snippet--stree"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-rust" data-lang="rust"><span class="line"><span class="cl"><span class="sd">/// N: #elements in a node, always 16.
</span></span></span><span class="line"><span class="cl"><span class="sd">/// B: branching factor &lt;= N+1. Typically 17.
</span></span></span><span class="line"><span class="cl"><span class="sd"></span><span class="k">pub</span><span class="w"> </span><span class="k">struct</span> <span class="nc">STree</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="n">B</span>: <span class="kt">usize</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">N</span>: <span class="kt">usize</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="sd">/// The list of tree nodes.
</span></span></span><span class="line"><span class="cl"><span class="sd"></span><span class="w">    </span><span class="n">tree</span>: <span class="nb">Vec</span><span class="o">&lt;</span><span class="n">TreeNode</span><span class="o">&lt;</span><span class="n">N</span><span class="o">&gt;&gt;</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="sd">/// The root is at index tree[offsets[0]].
</span></span></span><span class="line"><span class="cl"><span class="sd"></span><span class="w">    </span><span class="sd">/// It's children start at tree[offsets[1]], and so on.
</span></span></span><span class="line"><span class="cl"><span class="sd"></span><span class="w">    </span><span class="n">offsets</span>: <span class="nb">Vec</span><span class="o">&lt;</span><span class="kt">usize</span><span class="o">&gt;</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--stree">Code Snippet 6</a>:</span>
The S-tree data structure. It depends on the number of values per node <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="30" style="font-size: 119.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi></math></mjx-assistive-mml></mjx-container> (usually 16 but sometimes 15) and the size of each node <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="31" style="font-size: 119.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>N</mi></math></mjx-assistive-mml></mjx-container> (always 16).</div><p>To save some space, and focus on the interesting part (to me, at least), I will
not show any code for constructing S-trees. It’s a whole bunch of uninteresting
fiddling with indices, and takes a lot of time to get right. Also, construction
is not optimized at all currently. Anyway, find the code <a href="https://github.com/RagnarGrootKoerkamp/suffix-array-searching/tree/master/static-search-tree/src">here</a>.</p><p>TODO: Reverse offsets.</p><p>What we <em>will</em> look at, is code for searching S-trees.</p><p><a id="code-snippet--search-one"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-rust" data-lang="rust"><span class="line"><span class="cl"><span class="k">fn</span> <span class="nf">search</span><span class="p">(</span><span class="o">&amp;</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">q</span>: <span class="kt">u32</span><span class="p">,</span><span class="w"> </span><span class="n">find</span>: <span class="nc">impl</span><span class="w"> </span><span class="nb">Fn</span><span class="p">(</span><span class="o">&amp;</span><span class="n">TreeNode</span><span class="o">&lt;</span><span class="n">N</span><span class="o">&gt;</span><span class="p">,</span><span class="w"> </span><span class="kt">u32</span><span class="p">)</span><span class="w"> </span>-&gt; <span class="kt">usize</span><span class="p">)</span><span class="w"> </span>-&gt; <span class="kt">u32</span> <span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="k">mut</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">o</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">offsets</span><span class="p">[</span><span class="mi">0</span><span class="o">..</span><span class="bp">self</span><span class="p">.</span><span class="n">offsets</span><span class="p">.</span><span class="n">len</span><span class="p">()</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">jump_to</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">find</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">node</span><span class="p">(</span><span class="n">o</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">k</span><span class="p">),</span><span class="w"> </span><span class="n">q</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">B</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">jump_to</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">o</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">offsets</span><span class="p">.</span><span class="n">last</span><span class="p">().</span><span class="n">unwrap</span><span class="p">();</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c1">// node(i) returns tree[i] using unchecked indexing.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="k">mut</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">find</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">node</span><span class="p">(</span><span class="n">o</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">k</span><span class="p">),</span><span class="w"> </span><span class="n">q</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c1">// get(i, j) returns tree[i].data[j] using unchecked indexing.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">    </span><span class="bp">self</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">o</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">N</span><span class="p">)</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--search-one">Code Snippet 7</a>:</span>
Initial code for searching S-trees, directly adapted from <a href="https://en.algorithmica.org/hpc/data-structures/s-tree/#searching">https://en.algorithmica.org/hpc/data-structures/s-tree/#searching</a>. The <code>find</code> function finds the index of the child of the current node.</div><p>Our first step will be optimizing the <code>find</code> function.</p><h1 id="optimizing-find"><span class="section-num">2</span> Optimizing <code>find</code>
<a class="heading-link" href="#optimizing-find"><i class="fa fa-link" aria-hidden="true"></i></a></h1><h2 id="linear"><span class="section-num">2.1</span> Linear
<a class="heading-link" href="#linear"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>Let’s first precisely define what we want <code>find</code> to do:
it’s input is a node with 16 sorted values and a query value <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="32" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></mjx-assistive-mml></mjx-container>, and it should return
the index of the first element that is at least <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="33" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></mjx-assistive-mml></mjx-container>.</p><p>Some simple code for this is <a href="#code-snippet--find-linear">Code Snippet 8</a>.</p><p><a id="code-snippet--find-linear"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-rust" data-lang="rust"><span class="line"><span class="cl"><span class="k">pub</span><span class="w"> </span><span class="k">fn</span> <span class="nf">find_linear</span><span class="p">(</span><span class="o">&amp;</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">q</span>: <span class="kt">u32</span><span class="p">)</span><span class="w"> </span>-&gt; <span class="kt">usize</span> <span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="mi">0</span><span class="o">..</span><span class="n">N</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">q</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">i</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">N</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--find-linear">Code Snippet 8</a>:</span>
A linear scan for the first element <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="34" style="font-size: 119.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2265"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>≥</mo><mi>q</mi></math></mjx-assistive-mml></mjx-container>, that breaks as soon as it is found.</div><p>The results are not very impressive yet.</p><figure class="inset large"><a href="/ox-hugo/2-find-linear.svg"><img src="/ox-hugo/2-find-linear.svg" alt="Figure 5: The initial version of our S-tree search is quite a bit slower than the Eytzinger layout. In this and following plots, ‘old’ lines will be dimmed, and the best previous and best new line slightly highlighted. Colours will be consistent from one plot to the next."></a><figcaption><p><span class="figure-number">Figure 5: </span>The initial version of our S-tree search is quite a bit slower than the Eytzinger layout. In this and following plots, ‘old’ lines will be dimmed, and the best previous and best new line slightly highlighted. Colours will be consistent from one plot to the next.</p></figcaption></figure><h2 id="auto-vectorization"><span class="section-num">2.2</span> Auto-vectorization
<a class="heading-link" href="#auto-vectorization"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>As it turns out, the <code>break;</code> in <a href="#code-snippet--find-linear">Code Snippet 8</a> is really bad for performance,
since the branch predictor can’t do a good job on it.</p><p>Instead, we can <em>count</em> the number of values less than <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="35" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></mjx-assistive-mml></mjx-container>, and return that as
the index of the first value <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="36" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2265"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>≥</mo><mi>q</mi></math></mjx-assistive-mml></mjx-container>. (Example: all values <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="37" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2265"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>≥</mo><mi>q</mi></math></mjx-assistive-mml></mjx-container> index
gives index 0.)</p><p><a id="code-snippet--linear-count"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-rust" data-lang="rust"><span class="line"><span class="cl"><span class="k">pub</span><span class="w"> </span><span class="k">fn</span> <span class="nf">find_linear_count</span><span class="p">(</span><span class="o">&amp;</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">q</span>: <span class="kt">u32</span><span class="p">)</span><span class="w"> </span>-&gt; <span class="kt">usize</span> <span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="k">mut</span><span class="w"> </span><span class="n">count</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="mi">0</span><span class="o">..</span><span class="n">N</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">q</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="n">count</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">count</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--linear-count">Code Snippet 9</a>:</span>
Counting values <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="38" style="font-size: 119.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c3C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&lt;</mo><mi>q</mi></math></mjx-assistive-mml></mjx-container> instead of an early break. The <code>if self.data[i] &lt; q</code> can be optimized into branchless code.</div><p>In fact, the code is not just branchless, but actually it’s auto-vectorized into
SIMD instructions!</p><p><a id="code-snippet--linear-count-asm"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-asm" data-lang="asm"><span class="line"><span class="cl"><span class="nf">vmovdqu</span>      <span class="p">(</span><span class="nv">%rax</span><span class="p">,</span><span class="nv">%rcx</span><span class="p">),</span> <span class="nv">%ymm1</span>     <span class="c1">; load data[..8]
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vmovdqu</span>      <span class="mi">32</span><span class="p">(</span><span class="nv">%rax</span><span class="p">,</span><span class="nv">%rcx</span><span class="p">),</span> <span class="nv">%ymm2</span>   <span class="c1">; load data[8..]
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vpbroadcastd</span> <span class="nv">%xmm0</span><span class="p">,</span> <span class="nv">%ymm0</span>           <span class="c1">; 'splat' the query value
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vpmaxud</span>      <span class="nv">%ymm0</span><span class="p">,</span> <span class="nv">%ymm2</span><span class="p">,</span> <span class="nv">%ymm3</span>    <span class="c1">; v
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vpcmpeqd</span>     <span class="nv">%ymm3</span><span class="p">,</span> <span class="nv">%ymm2</span><span class="p">,</span> <span class="nv">%ymm2</span>    <span class="c1">; v
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vpmaxud</span>      <span class="nv">%ymm0</span><span class="p">,</span> <span class="nv">%ymm1</span><span class="p">,</span> <span class="nv">%ymm0</span>    <span class="c1">; v
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vpcmpeqd</span>     <span class="nv">%ymm0</span><span class="p">,</span> <span class="nv">%ymm1</span><span class="p">,</span> <span class="nv">%ymm0</span>    <span class="c1">; 4x compare query with values
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vpackssdw</span>    <span class="nv">%ymm2</span><span class="p">,</span> <span class="nv">%ymm0</span><span class="p">,</span> <span class="nv">%ymm0</span>    <span class="c1">;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vpcmpeqd</span>     <span class="nv">%ymm1</span><span class="p">,</span> <span class="nv">%ymm1</span><span class="p">,</span> <span class="nv">%ymm1</span>    <span class="c1">; v
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vpxor</span>        <span class="nv">%ymm1</span><span class="p">,</span> <span class="nv">%ymm0</span><span class="p">,</span> <span class="nv">%ymm0</span>    <span class="c1">; 2x negate result
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vextracti128</span> <span class="no">$1</span><span class="p">,</span> <span class="nv">%ymm0</span><span class="p">,</span> <span class="nv">%xmm1</span>       <span class="c1">; v
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vpacksswb</span>    <span class="nv">%xmm1</span><span class="p">,</span> <span class="nv">%xmm0</span><span class="p">,</span> <span class="nv">%xmm0</span>    <span class="c1">; v
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vpshufd</span>      <span class="no">$216</span><span class="p">,</span> <span class="nv">%xmm0</span><span class="p">,</span> <span class="nv">%xmm0</span>     <span class="c1">; v
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vpmovmskb</span>    <span class="nv">%xmm0</span><span class="p">,</span> <span class="nv">%ecx</span>            <span class="c1">; 4x extract mask
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">popcntl</span>      <span class="nv">%ecx</span><span class="p">,</span> <span class="nv">%ecx</span>             <span class="c1">; popcount the 16bit mask
</span></span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--linear-count-asm">Code Snippet 10</a>:</span>
Code Snippet <a href="#org580fb2e">9</a> is auto-vectorized!</div><p>To save some space: you can find this and further results for this section in
<a href="#figure--find-results">Figure 34</a> at the end of the section.</p><p>This auto-vectorized version is over two times faster than the linear find,
and now clearly beats Eytzinger layout!</p><h2 id="trailing-zeros"><span class="section-num">2.3</span> Trailing zeros
<a class="heading-link" href="#trailing-zeros"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>We can also roll our own SIMD. The SIMD version of the original linear scan idea
does 16 comparisons in parallel, converts that to a bitmask, and then counts the
number of trailing zeros. Using <code>#[feature(portable_simd)]</code>, that looks like this:</p><p><a id="code-snippet--find-ctz"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-rust" data-lang="rust"><span class="line"><span class="cl"><span class="k">pub</span><span class="w"> </span><span class="k">fn</span> <span class="nf">find_ctz</span><span class="p">(</span><span class="o">&amp;</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">q</span>: <span class="kt">u32</span><span class="p">)</span><span class="w"> </span>-&gt; <span class="kt">usize</span> <span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">data</span>: <span class="nc">Simd</span><span class="o">&lt;</span><span class="kt">u32</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">&gt;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Simd</span>::<span class="n">from_slice</span><span class="p">(</span><span class="o">&amp;</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="o">..</span><span class="n">N</span><span class="p">]);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">q</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Simd</span>::<span class="n">splat</span><span class="p">(</span><span class="n">q</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">mask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">q</span><span class="p">.</span><span class="n">simd_le</span><span class="p">(</span><span class="n">data</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">mask</span><span class="p">.</span><span class="n">first_set</span><span class="p">().</span><span class="n">unwrap_or</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--find-ctz">Code Snippet 11</a>:</span>
A <code>find</code> implementation using the <i>count-trailing-zeros</i> instruction.</div><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-asm" data-lang="asm"><span class="line"><span class="cl"><span class="nf">vpminud</span>      <span class="mi">32</span><span class="p">(</span><span class="nv">%rsi</span><span class="p">,</span><span class="nv">%r8</span><span class="p">),</span> <span class="nv">%ymm0</span><span class="p">,</span> <span class="nv">%ymm1</span>  <span class="c1">; take min of data[8..] and query
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vpcmpeqd</span>     <span class="nv">%ymm1</span><span class="p">,</span> <span class="nv">%ymm0</span><span class="p">,</span> <span class="nv">%ymm1</span>         <span class="c1">; does the min equal query?
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vpminud</span>      <span class="p">(</span><span class="nv">%rsi</span><span class="p">,</span><span class="nv">%r8</span><span class="p">),</span> <span class="nv">%ymm0</span><span class="p">,</span> <span class="nv">%ymm2</span>    <span class="c1">; take min of data[..8] and query
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vpcmpeqd</span>     <span class="nv">%ymm2</span><span class="p">,</span> <span class="nv">%ymm0</span><span class="p">,</span> <span class="nv">%ymm2</span>         <span class="c1">; does the min equal query?
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vpackssdw</span>    <span class="nv">%ymm1</span><span class="p">,</span> <span class="nv">%ymm2</span><span class="p">,</span> <span class="nv">%ymm1</span>         <span class="c1">; pack the two results together, interleaved as 16bit words
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vextracti128</span> <span class="no">$1</span><span class="p">,</span> <span class="nv">%ymm1</span><span class="p">,</span> <span class="nv">%xmm2</span>            <span class="c1">; extract half (both halves are equal)
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vpacksswb</span>    <span class="nv">%xmm2</span><span class="p">,</span> <span class="nv">%xmm1</span><span class="p">,</span> <span class="nv">%xmm1</span>         <span class="c1">; go down to 8bit values, but weirdly shuffled
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vpshufd</span>      <span class="no">$216</span><span class="p">,</span> <span class="nv">%xmm1</span><span class="p">,</span> <span class="nv">%xmm1</span>          <span class="c1">; unshuffle
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">vpmovmskb</span>    <span class="nv">%xmm1</span><span class="p">,</span> <span class="nv">%r8d</span>                 <span class="c1">; extract the high bit of each 8bit value.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">orl</span>          <span class="no">$65536</span><span class="p">,</span><span class="nv">%r8d</span>                 <span class="c1">; set bit 16, to cover the unwrap_or(N)
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">tzcntl</span>       <span class="nv">%r8d</span><span class="p">,</span><span class="nv">%r15d</span>                  <span class="c1">; count trailing zeros
</span></span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number">Code Snippet 12:</span>
Assembly code for Code Snippet <a href="#orge6452ef">11</a>. Instead of ending with <code>popcntl</code>, this ends with <code>tzcntl</code>.</div><p>Now, let’s look at this generated code in a bit more detail.</p><p>First up: why does <code>simd_le</code> translate into <code>min</code> and <code>cmpeq</code>?</p><p>From checking the <a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#=undefined&amp;techs=AVX_ALL&amp;text=_mm256_cmp">Intel Intrinsics Guide</a>, we find out that there are only signed
comparisons, while our data is unsigned. For now, let’s just assume that all
values fit in 31 bits and are at most <code>i32::MAX</code>. Then, we can transmute our input
to <code>Simd&lt;i32, 8&gt;</code> without changing its meaning.</p><div class="notice assumption"><div class="notice-title"><i class="fa fa-exclamation-triangle" aria-hidden="true"></i>Assumption</div><div class="notice-content"><p>Both input values and queries are between <code>0</code> and <code>i32::MAX</code>.</p><p>Eventually we can fix this by either taking <code>i32</code> input directly, or by shifting
<code>u32</code> values to fit in the <code>i32</code> range.</p></div></div><p><a id="code-snippet--ctz-signed"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="cl"> pub fn find_ctz_signed(&amp;self, q: u32) -&gt; usize
</span></span><span class="line"><span class="cl"> where
</span></span><span class="line"><span class="cl">     LaneCount&lt;N&gt;: SupportedLaneCount,
</span></span><span class="line"><span class="cl"> {
</span></span><span class="line"><span class="cl"><span class="gd">-    let data: Simd&lt;u32, N&gt; = Simd::from_slice(                   &amp;self.data[0..N]   );
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+    let data: Simd&lt;i32, N&gt; = Simd::from_slice(unsafe { transmute(&amp;self.data[0..N]) });
</span></span></span><span class="line"><span class="cl"><span class="gi"></span><span class="gd">-    let q = Simd::splat(q       );
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+    let q = Simd::splat(q as i32);
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>     let mask = q.simd_le(data);
</span></span><span class="line"><span class="cl">     mask.first_set().unwrap_or(N)
</span></span><span class="line"><span class="cl"> }
</span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--ctz-signed">Code Snippet 13</a>:</span>
Same as before, but now using <code>i32</code> values instead of <code>u32</code>.</div><p><a id="code-snippet--ctz-signed-asm"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="cl"><span class="gd">-vpminud      32(%rsi,%r8), %ymm0, %ymm1
</span></span></span><span class="line"><span class="cl"><span class="gd">-vpcmpeqd     %ymm1, %ymm0, %ymm1
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+vpcmpgtd     32(%rsi,%rdi), %ymm1, %ymm2 ; is query(%ymm1) &gt; data[8..]?
</span></span></span><span class="line"><span class="cl"><span class="gi"></span><span class="gd">-vpminud      (%rsi,%r8), %ymm0, %ymm2
</span></span></span><span class="line"><span class="cl"><span class="gd">-vpcmpeqd     %ymm2, %ymm0, %ymm2
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+vpcmpgtd     (%rsi,%rdi), %ymm1, %ymm1   ; is query(%ymm1) &gt; data[..8]?
</span></span></span><span class="line"><span class="cl"><span class="gi"></span> vpackssdw    %ymm2, %ymm1, %ymm1         ; pack results
</span></span><span class="line"><span class="cl"><span class="gi">+vpxor        %ymm0, %ymm1, %ymm1         ; negate results (ymm0 is all-ones)
</span></span></span><span class="line"><span class="cl"><span class="gi"></span> vextracti128 $1, %ymm1, %xmm2            ; extract u16x16
</span></span><span class="line"><span class="cl"> vpacksswb    %xmm2, %xmm1, %xmm1         ; shuffle
</span></span><span class="line"><span class="cl"> vpshufd      $216, %xmm1, %xmm1          ; extract u8x16
</span></span><span class="line"><span class="cl"> vpmovmskb    %xmm1, %edi                 ; extract u16 mask
</span></span><span class="line"><span class="cl"> orl          $65536,%edi                 ; add bit to get 16 when none set
</span></span><span class="line"><span class="cl"> tzcntl       %edi,%edi                   ; count trailing zeros
</span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--ctz-signed-asm">Code Snippet 14</a>:</span>
The two <code>vpminud</code> and <code>vpcmpeqd</code> instructions are gone now and merged into <code>vpcmpgtd</code>, but instead we got a <code>vpxor</code> back :/ (Ignore the different registers being used in the old versus the new version.)</div><p>It turns out there is only a <code>&gt;</code> instruction in SIMD, and not <code>&gt;=</code>, and so there
is no way to avoid inverting the result.</p><p>We also see a <code>vpshufd</code> instruction that feels <em>very</em> out of place. What’s
happening is that while packing the result of the 16 <code>u32</code> comparisons down to a
single 16bit value, data is interleaved in an unfortunate way, and we need to
fix that.
Here, Algorithmica takes the approach of ‘pre-shuffling’ the values in each
node to counter for the unshuffle instruction.
They also suggest using <code>popcount</code> instead, which is indeed what we’ll do next.</p><h2 id="popcount"><span class="section-num">2.4</span> Popcount
<a class="heading-link" href="#popcount"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>As we saw, the drawback of the trailing zero count approach is that the order of
the lanes must be preserved. Instead, we’ll now simply count the number of lanes
with a value less than the query, similar to the auto-vectorized SIMD before,
so that the order of lanes doesn’t matter.</p><p><a id="code-snippet--popcount-1"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="cl"> pub fn find_popcnt_portable(&amp;self, q: u32) -&gt; usize
</span></span><span class="line"><span class="cl"> where
</span></span><span class="line"><span class="cl">     LaneCount&lt;N&gt;: SupportedLaneCount,
</span></span><span class="line"><span class="cl"> {
</span></span><span class="line"><span class="cl">     let data: Simd&lt;i32, N&gt; = Simd::from_slice(unsafe { transmute(&amp;self.data[0..N]) });
</span></span><span class="line"><span class="cl">     let q = Simd::splat(q as i32);
</span></span><span class="line"><span class="cl"><span class="gd">-    let mask = q.simd_le(data);
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+    let mask = q.simd_gt(data);
</span></span></span><span class="line"><span class="cl"><span class="gi"></span><span class="gd">-    mask.first_set().unwrap_or(N)
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+    mask.to_bitmask().count_ones() as usize
</span></span></span><span class="line"><span class="cl"><span class="gi"></span> }
</span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--popcount-1">Code Snippet 15</a>:</span>
Using popcount instead of trailing zeros.</div><p><a id="code-snippet--popcount-1-asm"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="cl"> vpcmpgtd     32(%rsi,%rdi), %ymm0, %ymm1
</span></span><span class="line"><span class="cl"> vpcmpgtd     (%rsi,%rdi), %ymm0, %ymm0
</span></span><span class="line"><span class="cl"> vpackssdw    %ymm1, %ymm0, %ymm0     ; 1
</span></span><span class="line"><span class="cl"><span class="gd">-vpxor        %ymm0, %ymm1, %ymm1
</span></span></span><span class="line"><span class="cl"><span class="gd"></span> vextracti128 $1, %ymm0, %xmm1        ; 2
</span></span><span class="line"><span class="cl"> vpacksswb    %xmm1, %xmm0, %xmm0     ; 3
</span></span><span class="line"><span class="cl"> vpshufd      $216, %xmm0, %xmm0      ; 4
</span></span><span class="line"><span class="cl"> vpmovmskb    %xmm0, %edi             ; 5
</span></span><span class="line"><span class="cl"><span class="gd">-orl          $65536,%edi
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+popcntl      %edi, %edi
</span></span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--popcount-1-asm">Code Snippet 16</a>:</span>
the <code>xor</code> and <code>or</code> instructions are gone, but we are still stuck with the sequence of 5 instructions to go from the comparison results to an integer bitmask.</div><p>Ideally we would like to <code>movmsk</code> directly on the <code>u16x16</code> output of the first
pack instruction, <code>vpackssdw</code>, to get the highest bit of each of the 16 16-bit values.
Unfortunately, we are again let down by AVX2: there are <code>movemask</code> <a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#=undefined&amp;techs=AVX_ALL&amp;text=movms">instructions</a>
for <code>u8</code>, <code>u32</code>, and <code>u64</code>, but not for <code>u16</code>.</p><p>Also, the <code>vpshufd</code> instruction is now provably useless, so it’s slightly
disappointing the compiler didn’t elide it. Time to write the SIMD by hand instead.</p><h2 id="manual-simd"><span class="section-num">2.5</span> Manual SIMD
<a class="heading-link" href="#manual-simd"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>As it turns out, we can get away without most of the packing!
Instead of using <code>vpmovmskb</code> (<code>_mm256_movemask_epi8</code>) on 8bit data, we can
actually just use it directly on the 16bit output of <code>vpackssdw</code>!
Since the comparison sets each lane to all-zeros or all-ones, we can safely read
the most significant <em>and</em> middle bit, and divide the count by two at the
end.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a><span class="fn-tooltip"><span class="fn-number">4</span><span class="fn-text"><p>It would be really cool if we could teach compilers this trick. It already
auto-vectorized the counting code anyway, so this is not that much more work I’d
say.&nbsp;</p></span></span></sup></p><p><a id="code-snippet--popcount"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-rust" data-lang="rust"><span class="line"><span class="cl"><span class="k">pub</span><span class="w"> </span><span class="k">fn</span> <span class="nf">find_popcnt</span><span class="p">(</span><span class="o">&amp;</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">q</span>: <span class="kt">u32</span><span class="p">)</span><span class="w"> </span>-&gt; <span class="kt">usize</span> <span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c1">// We explicitly require that N is 16.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">low</span>: <span class="nc">Simd</span><span class="o">&lt;</span><span class="kt">u32</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="o">&gt;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Simd</span>::<span class="n">from_slice</span><span class="p">(</span><span class="o">&amp;</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="o">..</span><span class="n">N</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">2</span><span class="p">]);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">high</span>: <span class="nc">Simd</span><span class="o">&lt;</span><span class="kt">u32</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="o">&gt;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Simd</span>::<span class="n">from_slice</span><span class="p">(</span><span class="o">&amp;</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">N</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">2</span><span class="o">..</span><span class="n">N</span><span class="p">]);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">q_simd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Simd</span>::<span class="o">&lt;</span><span class="n">_</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="o">&gt;</span>::<span class="n">splat</span><span class="p">(</span><span class="n">q</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="kt">i32</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">unsafe</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="k">use</span><span class="w"> </span><span class="n">std</span>::<span class="n">mem</span>::<span class="n">transmute</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">t</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c1">// Transmute from u32 to i32.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">mask_low</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">q_simd</span><span class="p">.</span><span class="n">simd_gt</span><span class="p">(</span><span class="n">t</span><span class="p">(</span><span class="n">low</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">mask_high</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">q_simd</span><span class="p">.</span><span class="n">simd_gt</span><span class="p">(</span><span class="n">t</span><span class="p">(</span><span class="n">high</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c1">// Transmute from portable_simd to __m256i intrinsic types.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">merged</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">_mm256_packs_epi32</span><span class="p">(</span><span class="n">t</span><span class="p">(</span><span class="n">mask_low</span><span class="p">),</span><span class="w"> </span><span class="n">t</span><span class="p">(</span><span class="n">mask_high</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c1">// 32 bits is sufficient to hold a count of 2 per lane.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">mask</span>: <span class="kt">i32</span> <span class="o">=</span><span class="w"> </span><span class="n">_mm256_movemask_epi8</span><span class="p">(</span><span class="n">t</span><span class="p">(</span><span class="n">merged</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">mask</span><span class="p">.</span><span class="n">count_ones</span><span class="p">()</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="kt">usize</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">2</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--popcount">Code Snippet 17</a>:</span>
Manual version of the SIMD code, by explicitly using the intrinsics. This is kinda ugly now, and there's a lot of transmuting (casting) going on between <code>[u32; 8]</code>, <code>Simd&lt;u32, 8&gt;</code> and the native <code>__m256i</code> type, but we'll have to live with it.</div><p><a id="code-snippet--popcount-asm"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="cl"> vpcmpgtd     (%rsi,%rdi), %ymm0, %ymm1
</span></span><span class="line"><span class="cl"> vpcmpgtd     32(%rsi,%rdi), %ymm0, %ymm0
</span></span><span class="line"><span class="cl"> vpackssdw    %ymm0, %ymm1, %ymm0
</span></span><span class="line"><span class="cl"><span class="gd">-vextracti128 $1, %ymm0, %xmm1
</span></span></span><span class="line"><span class="cl"><span class="gd">-vpacksswb    %xmm1, %xmm0, %xmm0
</span></span></span><span class="line"><span class="cl"><span class="gd">-vpshufd      $216, %xmm0, %xmm0
</span></span></span><span class="line"><span class="cl"><span class="gd">-vpmovmskb    %xmm0, %edi
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+vpmovmskb    %ymm0, %edi
</span></span></span><span class="line"><span class="cl"><span class="gi"></span> popcntl      %edi, %edi
</span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--popcount-asm">Code Snippet 18</a>:</span>
Only 5 instructions total are left now. Note that there is no explicit division by 2, since this is absorbed into the pointer arithmetic in the remainder, after the function is inlined.</div><p>Now let’s have a look at the results of all this work.</p><p><a id="figure--find-results"></a></p><figure class="inset large"><a href="/ox-hugo/3-find.svg"><img src="/ox-hugo/3-find.svg" alt="Figure 6: Using the S-tree with an optimized find function improves throughput from 240ns/query for Eytzinger to 140ns/query for the auto-vectorized one, and down to 115ns/query for the final hand-optimized version, which is over 2x speedup!"></a><figcaption><p><span class="figure-number">Figure 6: </span>Using the S-tree with an optimized <code>find</code> function improves throughput from <code>240ns/query</code> for Eytzinger to <code>140ns/query</code> for the auto-vectorized one, and down to <code>115ns/query</code> for the final hand-optimized version, which is over 2x speedup!</p></figcaption></figure><p>As can be seen very nicely in this plot, each single instruction that we remove
gives a small but consistent improvement in throughput. The biggest improvement
comes from the last step, where we indeed shaved off 3 instructions.</p><p>In fact, we can analyse this plot a bit more:</p><ul><li>For input up to <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="39" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-script></mjx-msup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c36"></mjx-c><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mn>6</mn></msup><mo>=</mo><mn>64</mn></math></mjx-assistive-mml></mjx-container> bytes, the performance is constant, since in this
case the ‘search tree’ only consists of the root node.</li><li>Up to input of size <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="40" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mrow data-mjx-texclass="ORD"><mn>10</mn></mrow></msup></math></mjx-assistive-mml></mjx-container>, the thee has two layers, and the performance is constant.</li><li>Similarly, we see the latency jumping up at size <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="41" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mrow data-mjx-texclass="ORD"><mn>14</mn></mrow></msup></math></mjx-assistive-mml></mjx-container>, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="42" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mrow data-mjx-texclass="ORD"><mn>18</mn></mrow></msup></math></mjx-assistive-mml></mjx-container>, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="43" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mrow data-mjx-texclass="ORD"><mn>22</mn></mrow></msup></math></mjx-assistive-mml></mjx-container>
and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="44" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mrow data-mjx-texclass="ORD"><mn>26</mn></mrow></msup></math></mjx-assistive-mml></mjx-container>, each time because a new layer is added to the tree. (Or rather,
the jumps are at powers of the branching factor <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="45" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c37"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi><mo>+</mo><mn>1</mn><mo>=</mo><mn>17</mn></math></mjx-assistive-mml></mjx-container> instead of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="46" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-script></mjx-msup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mn>4</mn></msup><mo>=</mo><mn>16</mn></math></mjx-assistive-mml></mjx-container>, but you get the idea.)</li><li>In a way, we can also (handwaivily) interpret the x-axis as time: each time
the graph jumps up, the height of the jump is pretty much the time spent on
processing that one extra layer of the tree.</li><li>Once we exceed the size of L3 cache, things slow down quickly. At that
point, each extra layer of the tree adds a significant amount of time, since
waiting for RAM is inherently slow.</li><li>On the other hand, once we hit RAM, the slowdown is more smooth rather than
stepwise. This is because L3 is still able to cache a fraction of the
data structure, and that fraction only decreases slowly.</li><li>Again handwavily, we can also interpret the x-axis as a snapshot of space
usage at a fixed moment in time: the first three layers of the tree fit in L1.
The 4th and 5th layers fit in L2 and L3. Once the three is 6 layers deep, the
reads of that layer will mostly hit RAM, and any additional layers for sure
are going to RAM.</li></ul><p>From now on, this last version, <code>find_popcnt</code>, is the one we will be using.</p><h1 id="optimizing-the-search"><span class="section-num">3</span> Optimizing the search
<a class="heading-link" href="#optimizing-the-search"><i class="fa fa-link" aria-hidden="true"></i></a></h1><h2 id="batching"><span class="section-num">3.1</span> Batching
<a class="heading-link" href="#batching"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>As promised, the first improvement we’ll make is <em>batching</em>.
Instead of processing one query at a time, we can process multiple (many) queries
at once. This allows the CPU to work on multiple queries at the same time, and
in particular, it can have multiple (up to 10-12) in-progress requests to RAM at
a time. That way, instead of waiting for a latency of 80ns per read, we
effectively wait for 10 reads at the same time, lowering the amortized wait time
to around 8ns.</p><p>Batching very much benefits from the fact that we use an S+ tree instead of
S-tree, since each element is find in the last layer (at the same depth), and
hence the number of seach steps through the tree is the same for every element
in the batch.</p><p><a id="code-snippet--batch"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-rust" data-lang="rust"><span class="line"><span class="cl"><span class="k">fn</span> <span class="nf">batch</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="n">P</span>: <span class="kt">usize</span><span class="o">&gt;</span><span class="p">(</span><span class="o">&amp;</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">qb</span>: <span class="kp">&amp;</span><span class="p">[</span><span class="kt">u32</span><span class="p">;</span><span class="w"> </span><span class="n">P</span><span class="p">])</span><span class="w"> </span>-&gt; <span class="p">[</span><span class="kt">u32</span><span class="p">;</span><span class="w"> </span><span class="n">P</span><span class="p">]</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="k">mut</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">P</span><span class="p">];</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">[</span><span class="n">o</span><span class="p">,</span><span class="w"> </span><span class="n">_o2</span><span class="p">]</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">offsets</span><span class="p">.</span><span class="n">array_windows</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="mi">0</span><span class="o">..</span><span class="n">P</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="kd">let</span><span class="w"> </span><span class="n">jump_to</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">node</span><span class="p">(</span><span class="n">o</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]).</span><span class="n">find</span><span class="p">(</span><span class="n">qb</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">B</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">jump_to</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">o</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">offsets</span><span class="p">.</span><span class="n">last</span><span class="p">().</span><span class="n">unwrap</span><span class="p">();</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">from_fn</span><span class="p">(</span><span class="o">|</span><span class="n">i</span><span class="o">|</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">node</span><span class="p">(</span><span class="n">o</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]).</span><span class="n">find</span><span class="p">(</span><span class="n">qb</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="bp">self</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">o</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">N</span><span class="p">)</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">})</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--batch">Code Snippet 19</a>:</span>
The batching code is very similar to processing one query at a time. We just insert an additional loop over the batch of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="47" style="font-size: 119.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi></math></mjx-assistive-mml></mjx-container> items.</div><figure class="inset large"><a href="/ox-hugo/4-batching.svg"><img src="/ox-hugo/4-batching.svg" alt="Figure 7: Batch size 1 (red) performs very similar to our non-batched version (blue), around 115ns/query. Increasing the batch size to 2, 4, and 8 each time significantly improves performance, until it saturates at 45ns/query (2.5x faster) around 16."></a><figcaption><p><span class="figure-number">Figure 7: </span>Batch size 1 (red) performs very similar to our non-batched version (blue), around <code>115ns/query</code>. Increasing the batch size to 2, 4, and 8 each time significantly improves performance, until it saturates at <code>45ns/query</code> (2.5x faster) around 16.</p></figcaption></figure><p>One interesting observation is that going from batch size 1 to 2 does <em>not</em>
double the performance. I suspect this is because the CPU’s out-of-order
execution was already deep enough to effectively execute (almost) 2 queries in
parallel anyway. Going to a batch size of 4 and then 8 does provide a
significant speedup. Again going to 4 the speedup is relatively a bit less than
when going to 8, so probably even with batch size 4 the CPU is somewhat looking
ahead into the next batch of 4 already 🤯.</p><p>Throughput saturates at batch size 16 (or really, around 12 already), which
corresponds to the CPU having 12 <em>line fill buffers</em> and thus being able to
read up to 12 cache lines in parallel.</p><p>Nevertheless, we will settle on a batch size of 128, mostly because it leads to
slightly cleaner plots in the remainder. It is also every so slightly faster,
probably because the constant overhead of initializing a batch is smaller when
batches are larger.</p><h2 id="prefetching"><span class="section-num">3.2</span> Prefetching
<a class="heading-link" href="#prefetching"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>The CPU is already fetching multiple reads in parallel using out-of-order
execution, but we can also help out a bit by doing this explicitly using <em>prefetching</em>.
After processing a node, we determine the child node <code>k</code> that we need to visit
next, so we can directly request that node to be read from memory before
continuing with the rest of the batch.</p><p><a id="code-snippet--prefetch"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="cl"> fn batch&lt;const P: usize&gt;(&amp;self, qb: &amp;[u32; P]) -&gt; [u32; P] {
</span></span><span class="line"><span class="cl">     let mut k = [0; P];
</span></span><span class="line"><span class="cl">     for [o, o2] in self.offsets.array_windows() {
</span></span><span class="line"><span class="cl">         for i in 0..P {
</span></span><span class="line"><span class="cl">             let jump_to = self.node(o + k[i]).find(qb[i]);
</span></span><span class="line"><span class="cl">             k[i] = k[i] * (B + 1) + jump_to;
</span></span><span class="line"><span class="cl"><span class="gi">+            prefetch_index(&amp;self.tree, o2 + k[i]);
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>         }
</span></span><span class="line"><span class="cl">     }
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     let o = self.offsets.last().unwrap();
</span></span><span class="line"><span class="cl">     from_fn(|i| {
</span></span><span class="line"><span class="cl">         let idx = self.node(o + k[i]).find(qb[i]);
</span></span><span class="line"><span class="cl">         self.get(o + k[i] + idx / N, idx % N)
</span></span><span class="line"><span class="cl">     })
</span></span><span class="line"><span class="cl"> }
</span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--prefetch">Code Snippet 20</a>:</span>
Prefetching the cache line/node for the next iteration ahead.</div><figure class="inset large"><a href="/ox-hugo/5-prefetch.svg"><img src="/ox-hugo/5-prefetch.svg" alt="Figure 8: Prefetching helps speeding things up once the data does not fit in L2 cache anymore, and gets us down from 45ns/query to 30ns/query for 1GB input."></a><figcaption><p><span class="figure-number">Figure 8: </span>Prefetching helps speeding things up once the data does not fit in L2 cache anymore, and gets us down from <code>45ns/query</code> to <code>30ns/query</code> for <code>1GB</code> input.</p></figcaption></figure><p>We observe a few things: first prefetching slightly slow things down while data
fits in L1 already, since in that case the instruction just doesn’t do anything anyway.
In L2, it makes the graph slightly more flat, indicating that already there, the
latency is already a little bit of a bottleneck.
In L3 this effect gets larger, and we get a nice smooth/horizontal graph, until
we hit RAM size. There, prefetching provides the biggest gains.</p><h2 id="pointer-arithmetic"><span class="section-num">3.3</span> Pointer arithmetic
<a class="heading-link" href="#pointer-arithmetic"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>Again, it’s time to look at some assembly code, now to optimize the search
function itself. Results are down below in <a href="#figure--pointer-arithmetic">Figure 9</a>.</p><h3 id="up-front-splat"><span class="section-num">3.3.1</span> Up-front splat
<a class="heading-link" href="#up-front-splat"><i class="fa fa-link" aria-hidden="true"></i></a></h3><p>First, we can note that the <code>find</code> function <code>splat</code>’s the query from a <code>u32</code> to
a <code>Simd&lt;u32, 8&gt;</code> on each call. It’s slightly nicer (but not really faster,
actually) to splat all the queries
up-front, and then reuse those.</p><p><a id="code-snippet--splat"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="cl"> pub fn batch_splat&lt;const P: usize&gt;(&amp;self, qb: &amp;[u32; P]) -&gt; [u32; P] {
</span></span><span class="line"><span class="cl">     let mut k = [0; P];
</span></span><span class="line"><span class="cl"><span class="gi">+    let q_simd = qb.map(|q| Simd::&lt;u32, 8&gt;::splat(q));
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>
</span></span><span class="line"><span class="cl">     for [o, o2] in self.offsets.array_windows() {
</span></span><span class="line"><span class="cl">         for i in 0..P {
</span></span><span class="line"><span class="cl"><span class="gd">-            let jump_to = self.node(o + k[i]).find      (qb[i]    );
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+            let jump_to = self.node(o + k[i]).find_splat(q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>             k[i] = k[i] * (B + 1) + jump_to;
</span></span><span class="line"><span class="cl">             prefetch_index(&amp;self.tree, o2 + k[i]);
</span></span><span class="line"><span class="cl">         }
</span></span><span class="line"><span class="cl">     }
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     let o = self.offsets.last().unwrap();
</span></span><span class="line"><span class="cl">     from_fn(|i| {
</span></span><span class="line"><span class="cl"><span class="gd">-        let idx = self.node(o + k[i]).find      (qb[i]    );
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+        let idx = self.node(o + k[i]).find_splat(q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>         self.get(o + k[i] + idx / N, idx % N)
</span></span><span class="line"><span class="cl">     })
</span></span><span class="line"><span class="cl"> }
</span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--splat">Code Snippet 21</a>:</span>
<i>Hoisting</i> the <code>splat</code> out of the <i>loop</i> is slightly nicer, but not faster.</div><p>The assembly code for each iteration of the first loop now looks like this:</p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-asm" data-lang="asm"><span class="line"><span class="cl"><span class="nf">movq</span>         <span class="p">(</span><span class="nv">%rsp</span><span class="p">,</span><span class="nv">%r11</span><span class="p">),</span><span class="nv">%r15</span>
</span></span><span class="line"><span class="cl"><span class="nf">leaq</span>         <span class="p">(</span><span class="nv">%r9</span><span class="p">,</span><span class="nv">%r15</span><span class="p">),</span><span class="nv">%r12</span>
</span></span><span class="line"><span class="cl"><span class="nf">shlq</span>         <span class="no">$6</span><span class="p">,</span> <span class="nv">%r12</span>
</span></span><span class="line"><span class="cl"><span class="nf">vmovdqa</span>      <span class="mi">1536</span><span class="p">(</span><span class="nv">%rsp</span><span class="p">,</span><span class="nv">%r11</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span><span class="nv">%ymm0</span>
</span></span><span class="line"><span class="cl"><span class="nf">vpcmpgtd</span>     <span class="p">(</span><span class="nv">%rsi</span><span class="p">,</span><span class="nv">%r12</span><span class="p">),</span> <span class="nv">%ymm0</span><span class="p">,</span> <span class="nv">%ymm1</span>
</span></span><span class="line"><span class="cl"><span class="nf">vpcmpgtd</span>     <span class="mi">32</span><span class="p">(</span><span class="nv">%rsi</span><span class="p">,</span><span class="nv">%r12</span><span class="p">),</span> <span class="nv">%ymm0</span><span class="p">,</span> <span class="nv">%ymm0</span>
</span></span><span class="line"><span class="cl"><span class="nf">vpackssdw</span>    <span class="nv">%ymm0</span><span class="p">,</span> <span class="nv">%ymm1</span><span class="p">,</span> <span class="nv">%ymm0</span>
</span></span><span class="line"><span class="cl"><span class="nf">vpmovmskb</span>    <span class="nv">%ymm0</span><span class="p">,</span> <span class="nv">%r12d</span>
</span></span><span class="line"><span class="cl"><span class="nf">popcntl</span>      <span class="nv">%r12d</span><span class="p">,</span> <span class="nv">%r12d</span>
</span></span><span class="line"><span class="cl"><span class="nf">shrl</span>         <span class="nv">%r12d</span>
</span></span><span class="line"><span class="cl"><span class="nf">movq</span>         <span class="nv">%r15</span><span class="p">,</span><span class="nv">%r13</span>
</span></span><span class="line"><span class="cl"><span class="nf">shlq</span>         <span class="no">$4</span><span class="p">,</span> <span class="nv">%r13</span>
</span></span><span class="line"><span class="cl"><span class="nf">addq</span>         <span class="nv">%r15</span><span class="p">,</span><span class="nv">%r13</span>
</span></span><span class="line"><span class="cl"><span class="nf">addq</span>         <span class="nv">%r12</span><span class="p">,</span><span class="nv">%r13</span>
</span></span><span class="line"><span class="cl"><span class="nf">movq</span>         <span class="nv">%r13</span><span class="p">,(</span><span class="nv">%rsp</span><span class="p">,</span><span class="nv">%r11</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nf">shlq</span>         <span class="no">$6</span><span class="p">,</span> <span class="nv">%r13</span>
</span></span><span class="line"><span class="cl"><span class="nf">prefetcht0</span>   <span class="p">(</span><span class="nv">%r10</span><span class="p">,</span><span class="nv">%r13</span><span class="p">)</span>
</span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number">Code Snippet 22:</span>
Assembly code for each iteration of Code Snippet <a href="#orgaceea1d">21</a>. (Actually it's unrolled into two copied of this, but they're identical.)</div><h3 id="byte-based-pointers"><span class="section-num">3.3.2</span> Byte-based pointers
<a class="heading-link" href="#byte-based-pointers"><i class="fa fa-link" aria-hidden="true"></i></a></h3><p>Looking at the code above, we see two <code>shlq $6</code> instructions that multiply the
given value by <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="48" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c36"></mjx-c><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>64</mn></math></mjx-assistive-mml></mjx-container>. That’s because our tree nodes are 64 bytes large, and
hence, to get the <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="49" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi></math></mjx-assistive-mml></mjx-container>’th element of the array, we need to read at byte <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="50" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c36"></mjx-c><mjx-c class="mjx-c34"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>64</mn><mo>⋅</mo><mi>i</mi></math></mjx-assistive-mml></mjx-container>. For smaller element sizes, there are dedicated read instructions that
inline, say, an index multiplication by 8. But for a stride of 64, the compiler
has to generate ‘manual’ multiplications in the form of a shift.</p><p>Additionally, direct pointer-based lookups can be slightly more efficient here than
array-indexing: when doing <code>self.tree[o + k[i]]</code>, we can effectively pre-compute
the pointer to <code>self.tree[o]</code>, so that only <code>k[i]</code> still has to be added. Let’s
first look at that diff:</p><p><a id="code-snippet--ptr"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="cl"> pub fn batch_ptr&lt;const P: usize&gt;(&amp;self, qb: &amp;[u32; P]) -&gt; [u32; P] {
</span></span><span class="line"><span class="cl">     let mut k = [0; P];
</span></span><span class="line"><span class="cl">     let q_simd = qb.map(|q| Simd::&lt;u32, 8&gt;::splat(q));
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="gi">+    // offsets[l] is a pointer to self.tree[self.offsets[l]]
</span></span></span><span class="line"><span class="cl"><span class="gi">+    let offsets = self.offsets.iter()
</span></span></span><span class="line"><span class="cl"><span class="gi">+        .map(|o| unsafe { self.tree.as_ptr().add(*o) })
</span></span></span><span class="line"><span class="cl"><span class="gi">+        .collect_vec();
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>
</span></span><span class="line"><span class="cl">     for [o, o2] in offsets.array_windows() {
</span></span><span class="line"><span class="cl">         for i in 0..P {
</span></span><span class="line"><span class="cl"><span class="gd">-            let jump_to = self.node(o  +  k[i])  .find_splat(q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+            let jump_to = unsafe { *o.add(k[i]) }.find_splat(q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>             k[i] = k[i] * (B + 1) + jump_to;
</span></span><span class="line"><span class="cl"><span class="gd">-            prefetch_index(&amp;self.tree, o2 + k[i]);
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+            prefetch_ptr(unsafe { o2.add(k[i]) });
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>         }
</span></span><span class="line"><span class="cl">     }
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     let o = offsets.last().unwrap();
</span></span><span class="line"><span class="cl">     from_fn(|i| {
</span></span><span class="line"><span class="cl"><span class="gd">-        let idx = self.node(o  +  k[i])  .find_splat(q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+        let idx = unsafe { *o.add(k[i]) }.find_splat(q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gi"></span><span class="gd">-        self.get(o + k[i] + idx / N, idx % N)
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+        unsafe { *(*o.add(k[i] + idx / N)).data.get_unchecked(idx % N) }
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>     })
</span></span><span class="line"><span class="cl"> }
</span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--ptr">Code Snippet 23</a>:</span>
Using pointer-based indexing instead of array indexing.</div><p>Now, we can avoid all the multiplications by 64, by just multiplying all <code>k[i]</code>
by 64 to start with:</p><p><a id="code-snippet--ptr64"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="cl"> pub fn batch_byte_ptr&lt;const P: usize&gt;(&amp;self, qb: &amp;[u32; P]) -&gt; [u32; P] {
</span></span><span class="line"><span class="cl">     let mut k = [0; P];
</span></span><span class="line"><span class="cl">     let q_simd = qb.map(|q| Simd::&lt;u32, 8&gt;::splat(q));
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     let offsets = self
</span></span><span class="line"><span class="cl">         .offsets
</span></span><span class="line"><span class="cl">         .iter()
</span></span><span class="line"><span class="cl">         .map(|o| unsafe { self.tree.as_ptr().add(*o) })
</span></span><span class="line"><span class="cl">         .collect_vec();
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     for [o, o2] in offsets.array_windows() {
</span></span><span class="line"><span class="cl">         for i in 0..P {
</span></span><span class="line"><span class="cl"><span class="gd">-            let jump_to = unsafe { *o.     add(k[i]) }.find_splat(q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+            let jump_to = unsafe { *o.byte_add(k[i]) }.find_splat(q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gi"></span><span class="gd">-            k[i] = k[i] * (B + 1) + jump_to     ;
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+            k[i] = k[i] * (B + 1) + jump_to * 64;
</span></span></span><span class="line"><span class="cl"><span class="gi"></span><span class="gd">-            prefetch_ptr(unsafe { o2.     add(k[i]) });
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+            prefetch_ptr(unsafe { o2.byte_add(k[i]) });
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>         }
</span></span><span class="line"><span class="cl">     }
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     let o = offsets.last().unwrap();
</span></span><span class="line"><span class="cl">     from_fn(|i| {
</span></span><span class="line"><span class="cl"><span class="gd">-        let idx = unsafe { *o.     add(k[i]) }.find_splat(q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+        let idx = unsafe { *o.byte_add(k[i]) }.find_splat(q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gi"></span><span class="gd">-        unsafe { *(*o.add(k[i] + idx / N)).data.get_unchecked(idx % N) }
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+        unsafe { (o.byte_add(k[i]) as *const u32).add(idx).read() }
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>     })
</span></span><span class="line"><span class="cl"> }
</span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--ptr64">Code Snippet 24</a>:</span>
We multiply <code>k[i]</code> by 64 up-front, and then call <code>byte_add</code> instead of the usual <code>add</code>.</div><p>Indeed, the generated code now goes down from 17 to 15 instructions, and we can
see in <a href="#figure--pointer-arithmetic">Figure 9</a> that this gives a significant speedup!</p><p><a id="code-snippet--byte-ptr"></a></p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-asm" data-lang="asm"><span class="line"><span class="cl"><span class="nf">movq</span>         <span class="mi">32</span><span class="p">(</span><span class="nv">%rsp</span><span class="p">,</span><span class="nv">%rdi</span><span class="p">),</span><span class="nv">%r8</span>
</span></span><span class="line"><span class="cl"><span class="nf">vmovdqa</span>      <span class="mi">1568</span><span class="p">(</span><span class="nv">%rsp</span><span class="p">,</span><span class="nv">%rdi</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span><span class="nv">%ymm0</span>
</span></span><span class="line"><span class="cl"><span class="nf">vpcmpgtd</span>     <span class="p">(</span><span class="nv">%rsi</span><span class="p">,</span><span class="nv">%r8</span><span class="p">),</span> <span class="nv">%ymm0</span><span class="p">,</span> <span class="nv">%ymm1</span>
</span></span><span class="line"><span class="cl"><span class="nf">vpcmpgtd</span>     <span class="mi">32</span><span class="p">(</span><span class="nv">%rsi</span><span class="p">,</span><span class="nv">%r8</span><span class="p">),</span> <span class="nv">%ymm0</span><span class="p">,</span> <span class="nv">%ymm0</span>
</span></span><span class="line"><span class="cl"><span class="nf">vpackssdw</span>    <span class="nv">%ymm0</span><span class="p">,</span> <span class="nv">%ymm1</span><span class="p">,</span> <span class="nv">%ymm0</span>
</span></span><span class="line"><span class="cl"><span class="nf">vpmovmskb</span>    <span class="nv">%ymm0</span><span class="p">,</span> <span class="nv">%r9d</span>
</span></span><span class="line"><span class="cl"><span class="nf">popcntl</span>      <span class="nv">%r9d</span><span class="p">,</span> <span class="nv">%r9d</span>
</span></span><span class="line"><span class="cl"><span class="nf">movq</span>         <span class="nv">%r8</span><span class="p">,</span><span class="nv">%r10</span>
</span></span><span class="line"><span class="cl"><span class="nf">shlq</span>         <span class="no">$4</span><span class="p">,</span> <span class="nv">%r10</span>
</span></span><span class="line"><span class="cl"><span class="nf">addq</span>         <span class="nv">%r8</span><span class="p">,</span><span class="nv">%r10</span>
</span></span><span class="line"><span class="cl"><span class="nf">shll</span>         <span class="no">$5</span><span class="p">,</span> <span class="nv">%r9d</span>
</span></span><span class="line"><span class="cl"><span class="nf">andl</span>         <span class="no">$-64</span><span class="p">,</span><span class="nv">%r9d</span>
</span></span><span class="line"><span class="cl"><span class="nf">addq</span>         <span class="nv">%r10</span><span class="p">,</span><span class="nv">%r9</span>
</span></span><span class="line"><span class="cl"><span class="nf">movq</span>         <span class="nv">%r9</span><span class="p">,</span><span class="mi">32</span><span class="p">(</span><span class="nv">%rsp</span><span class="p">,</span><span class="nv">%rdi</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nf">prefetcht0</span>   <span class="p">(</span><span class="nv">%rcx</span><span class="p">,</span><span class="nv">%r9</span><span class="p">)</span>
</span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number"><a href="#code-snippet--byte-ptr">Code Snippet 25</a>:</span>
When using byte-based pointers, we avoid some multiplications by 64.</div><h3 id="the-final-version"><span class="section-num">3.3.3</span> The final version
<a class="heading-link" href="#the-final-version"><i class="fa fa-link" aria-hidden="true"></i></a></h3><p>One particularity about the code above is the <code>andl $-64,%r9d</code>.
In line 6, the bitmask gets written there. Then in line 7, it’s popcounted.
Life 11 does a <code>shll $5</code>, i.e., a multiplication by 32, which is a combination
of the <code>/2</code> to compensate for the double-popcount and the <code>* 64</code>. Then, it does
the <code>and $-64</code>, where the mask of -64 is <code>111..11000000</code> which ends in 6 zeros.
But we just multiplied by 32, so all this does is zeroing out a single bit, in
case the popcount was odd. But we know for a fact that that can never be, so we
don’t actually need this <code>and</code> instruction.</p><p>To avoid it, we do this <code>/2*64 =&gt; *32</code> optimization manually.</p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="cl"> pub fn find_splat64(&amp;self, q_simd: Simd&lt;u32, 8&gt;) -&gt; usize {
</span></span><span class="line"><span class="cl">     let low: Simd&lt;u32, 8&gt; = Simd::from_slice(&amp;self.data[0..N / 2]);
</span></span><span class="line"><span class="cl">     let high: Simd&lt;u32, 8&gt; = Simd::from_slice(&amp;self.data[N / 2..N]);
</span></span><span class="line"><span class="cl">     unsafe {
</span></span><span class="line"><span class="cl">         let q_simd: Simd&lt;i32, 8&gt; = t(q_simd);
</span></span><span class="line"><span class="cl">         let mask_low = q_simd.simd_gt(t(low));
</span></span><span class="line"><span class="cl">         let mask_high = q_simd.simd_gt(t(high));
</span></span><span class="line"><span class="cl">         use std::mem::transmute as t;
</span></span><span class="line"><span class="cl">         let merged = _mm256_packs_epi32(t(mask_low), t(mask_high));
</span></span><span class="line"><span class="cl">         let mask = _mm256_movemask_epi8(merged);
</span></span><span class="line"><span class="cl"><span class="gd">-        mask.count_ones() as usize / 2
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+        mask.count_ones() as usize * 32
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>     }
</span></span><span class="line"><span class="cl"> }
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> pub fn batch_byte_ptr&lt;const P: usize&gt;(&amp;self, qb: &amp;[u32; P]) -&gt; [u32; P] {
</span></span><span class="line"><span class="cl">     let mut k = [0; P];
</span></span><span class="line"><span class="cl">     let q_simd = qb.map(|q| Simd::&lt;u32, 8&gt;::splat(q));
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     let offsets = self
</span></span><span class="line"><span class="cl">         .offsets
</span></span><span class="line"><span class="cl">         .iter()
</span></span><span class="line"><span class="cl">         .map(|o| unsafe { self.tree.as_ptr().add(*o) })
</span></span><span class="line"><span class="cl">         .collect_vec();
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     for [o, o2] in offsets.array_windows() {
</span></span><span class="line"><span class="cl">         for i in 0..P {
</span></span><span class="line"><span class="cl"><span class="gd">-            let jump_to = unsafe { *o.byte_add(k[i]) }.find_splat  (q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+            let jump_to = unsafe { *o.byte_add(k[i]) }.find_splat64(q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gi"></span><span class="gd">-            k[i] = k[i] * (B + 1) + jump_to * 64;
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+            k[i] = k[i] * (B + 1) + jump_to     ;
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>             prefetch_ptr(unsafe { o2.byte_add(k[i]) });
</span></span><span class="line"><span class="cl">         }
</span></span><span class="line"><span class="cl">     }
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     let o = offsets.last().unwrap();
</span></span><span class="line"><span class="cl">     from_fn(|i| {
</span></span><span class="line"><span class="cl">         let idx = unsafe { *o.byte_add(k[i]) }.find_splat(q_simd[i]);
</span></span><span class="line"><span class="cl">         unsafe { (o.byte_add(k[i]) as *const u32).add(idx).read() }
</span></span><span class="line"><span class="cl">     })
</span></span><span class="line"><span class="cl"> }
</span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number">Code Snippet 26:</span>
Manually merging <code>/2</code> and <code>*64</code> into <code>*32</code>.</div><p>Again, this gives a small speedup.</p><p><a id="figure--pointer-arithmetic"></a></p><figure class="inset large"><a href="/ox-hugo/6-improvements.svg"><img src="/ox-hugo/6-improvements.svg" alt="Figure 9: Results of improving the search function bit by bit. Like before, the improvements are small but consistent. Throughput on 1GB input improves from 31ns/query to 28ns/query."></a><figcaption><p><span class="figure-number">Figure 9: </span>Results of improving the search function bit by bit. Like before, the improvements are small but consistent. Throughput on <code>1GB</code> input improves from <code>31ns/query</code> to <code>28ns/query</code>.</p></figcaption></figure><h2 id="skip-prefetch"><span class="section-num">3.4</span> Skip prefetch
<a class="heading-link" href="#skip-prefetch"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>Now we know that the first three levels of the graph fit in L1 cache, so
probably we can simply skip prefetching for those levels.</p><figure class="inset large"><a href="/ox-hugo/7-skip-prefetch.svg"><img src="/ox-hugo/7-skip-prefetch.svg" alt="Figure 10: Skipping the prefetch for the first layers is slightly slower."></a><figcaption><p><span class="figure-number">Figure 10: </span>Skipping the prefetch for the first layers is slightly slower.</p></figcaption></figure><p>As it turns out, skipping the prefetch does not help. Probably because the
prefetch is cheap if the data is already available, and there is a small chance
that the data we need was evicted to make room for other things, in which case
the prefetch <em>is</em> useful.</p><h2 id="interleave"><span class="section-num">3.5</span> Interleave
<a class="heading-link" href="#interleave"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>One other observation is that the first few layers are CPU bound, while the last
few layers are memory throughput bound.
By merging the two domains, we should be able to get a higher total throughput.
(Somewhat similar to how for a piece wise linear convex function <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="51" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi></math></mjx-assistive-mml></mjx-container>, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="52" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mi>y</mi><mo stretchy="false">)</mo><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mn>2</mn><mo stretchy="false">)</mo><mo>&lt;</mo><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mi>f</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mn>2</mn></math></mjx-assistive-mml></mjx-container> when <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="53" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="54" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi></math></mjx-assistive-mml></mjx-container> are on different pieces.)
Thus, maybe we could process two batches
of queries at the same time by processing layer <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="55" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi></math></mjx-assistive-mml></mjx-container> of one batch at the same
time as layer <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="56" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi><mo>+</mo><mi>L</mi><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mn>2</mn></math></mjx-assistive-mml></mjx-container> of the other batch (where <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="57" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>L</mi></math></mjx-assistive-mml></mjx-container> is the height of the tree).
I implemented this, but unfortunately the result is not faster than what we had.</p><p>Or maybe we can split the work as: interleave the last level of one half
with <em>all but the last</em> level of the other half? Since the last-level memory
read takes most of the time. Also that turns out slower in practice.</p><p>What does give a small speedup: process the first <em>two</em> levels of the next batch
interleaved with the last prefetch of the current batch. Still the result is
only around <code>2ns</code> speedup, while code the (not shown ;") gets significantly more
messy.</p><p>What <em>does</em> work great, is interleaving <em>all</em> layers of the search: when the
tree has <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="58" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>L</mi></math></mjx-assistive-mml></mjx-container> layers, we can interleave <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="59" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>L</mi></math></mjx-assistive-mml></mjx-container> batches at a time, and then process
layer <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="60" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi></math></mjx-assistive-mml></mjx-container> of the <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="61" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi></math></mjx-assistive-mml></mjx-container>’th in-progress batch. Then we ‘shift out’ the completed
batch and store the answers to those queries, and ‘shift in’ a new batch.
This we, completely average the different workloads of all the layers, and
should achieve near-optimal performance given the CPU’s memory bandwidth to L3
and RAM (at least, that’s what I assume is the bottleneck now).</p><details><summary>Click to show code for interleaving.</summary><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-rust" data-lang="rust"><span class="line"><span class="cl"><span class="k">pub</span><span class="w"> </span><span class="k">fn</span> <span class="nf">batch_interleave_full_128</span><span class="p">(</span><span class="o">&amp;</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">qs</span>: <span class="kp">&amp;</span><span class="p">[</span><span class="kt">u32</span><span class="p">])</span><span class="w"> </span>-&gt; <span class="nb">Vec</span><span class="o">&lt;</span><span class="kt">u32</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">match</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">offsets</span><span class="p">.</span><span class="n">len</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c1">// 1 batch of size 128
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">        </span><span class="mi">1</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">batch_interleave_full</span>::<span class="o">&lt;</span><span class="mi">128</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">128</span><span class="o">&gt;</span><span class="p">(</span><span class="n">qs</span><span class="p">),</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c1">// 2 batches of size 64 in parallel, with product 128
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">        </span><span class="mi">2</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">batch_interleave_full</span>::<span class="o">&lt;</span><span class="mi">64</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">128</span><span class="o">&gt;</span><span class="p">(</span><span class="n">qs</span><span class="p">),</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c1">// 3 batches of size 32 in parallel with product 96
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">        </span><span class="mi">3</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">batch_interleave_full</span>::<span class="o">&lt;</span><span class="mi">32</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">96</span><span class="o">&gt;</span><span class="p">(</span><span class="n">qs</span><span class="p">),</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="mi">4</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">batch_interleave_full</span>::<span class="o">&lt;</span><span class="mi">32</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">128</span><span class="o">&gt;</span><span class="p">(</span><span class="n">qs</span><span class="p">),</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="mi">5</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">batch_interleave_full</span>::<span class="o">&lt;</span><span class="mi">16</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">80</span><span class="o">&gt;</span><span class="p">(</span><span class="n">qs</span><span class="p">),</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="mi">6</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">batch_interleave_full</span>::<span class="o">&lt;</span><span class="mi">16</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="mi">96</span><span class="o">&gt;</span><span class="p">(</span><span class="n">qs</span><span class="p">),</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="mi">7</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">batch_interleave_full</span>::<span class="o">&lt;</span><span class="mi">16</span><span class="p">,</span><span class="w"> </span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="mi">112</span><span class="o">&gt;</span><span class="p">(</span><span class="n">qs</span><span class="p">),</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="mi">8</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">batch_interleave_full</span>::<span class="o">&lt;</span><span class="mi">16</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">,</span><span class="w"> </span><span class="mi">128</span><span class="o">&gt;</span><span class="p">(</span><span class="n">qs</span><span class="p">),</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">_</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="fm">panic!</span><span class="p">(</span><span class="s">"Unsupported tree height </span><span class="si">{}</span><span class="s">"</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">offsets</span><span class="p">.</span><span class="n">len</span><span class="p">()),</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">pub</span><span class="w"> </span><span class="k">fn</span> <span class="nf">batch_interleave_full</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="n">P</span>: <span class="kt">usize</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">L</span>: <span class="kt">usize</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="no">PL</span>: <span class="kt">usize</span><span class="o">&gt;</span><span class="p">(</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="o">&amp;</span><span class="bp">self</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">qs</span>: <span class="kp">&amp;</span><span class="p">[</span><span class="kt">u32</span><span class="p">],</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">)</span><span class="w"> </span>-&gt; <span class="nb">Vec</span><span class="o">&lt;</span><span class="kt">u32</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="fm">assert_eq!</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">offsets</span><span class="p">.</span><span class="n">len</span><span class="p">(),</span><span class="w"> </span><span class="n">L</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="k">mut</span><span class="w"> </span><span class="n">out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">Vec</span>::<span class="n">with_capacity</span><span class="p">(</span><span class="n">qs</span><span class="p">.</span><span class="n">len</span><span class="p">());</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="k">mut</span><span class="w"> </span><span class="n">ans</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">P</span><span class="p">];</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c1">// Iterate over chunks of size P of queries.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">    </span><span class="c1">// Omitted: initialize
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">first_i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">L</span><span class="o">-</span><span class="mi">1</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">chunk</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">qs</span><span class="p">.</span><span class="n">array_chunks</span>::<span class="o">&lt;</span><span class="n">P</span><span class="o">&gt;</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">first_i</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c1">// Decrement first_i, modulo L.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">first_i</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="n">first_i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">L</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">first_i</span><span class="w"> </span><span class="o">-=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c1">// Process 1 element per chunk, starting at element first_i.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">        </span><span class="c1">// (Omitted: process first up-to L elements.)
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">        </span><span class="c1">// Write output and read new queries from index j.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="k">mut</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="k">loop</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="c1">// First L-1 levels: do the usual thing.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">            </span><span class="c1">// The compiler will unroll this loop.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">l</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="mi">0</span><span class="o">..</span><span class="n">L</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                </span><span class="kd">let</span><span class="w"> </span><span class="n">jump_to</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">unsafe</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="o">*</span><span class="n">offsets</span><span class="p">[</span><span class="n">l</span><span class="p">].</span><span class="n">byte_add</span><span class="p">(</span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="w"> </span><span class="p">}.</span><span class="n">find_splat64</span><span class="p">(</span><span class="n">q_simd</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                </span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">B</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">jump_to</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                </span><span class="n">prefetch_ptr</span><span class="p">(</span><span class="k">unsafe</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">offsets</span><span class="p">[</span><span class="n">l</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">].</span><span class="n">byte_add</span><span class="p">(</span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="w"> </span><span class="p">});</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="c1">// Last level: read answer.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">            </span><span class="n">ans</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                </span><span class="kd">let</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">unsafe</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="o">*</span><span class="n">ol</span><span class="p">.</span><span class="n">byte_add</span><span class="p">(</span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="w"> </span><span class="p">}.</span><span class="n">find_splat</span><span class="p">(</span><span class="n">q_simd</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                </span><span class="k">unsafe</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="p">(</span><span class="n">ol</span><span class="p">.</span><span class="n">byte_add</span><span class="p">(</span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="o">*</span><span class="k">const</span><span class="w"> </span><span class="kt">u32</span><span class="p">).</span><span class="n">add</span><span class="p">(</span><span class="n">idx</span><span class="p">).</span><span class="n">read</span><span class="p">()</span><span class="w"> </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="p">};</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="c1">// Last level: reset index, and read new query.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">            </span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="n">q_simd</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Simd</span>::<span class="n">splat</span><span class="p">(</span><span class="n">chunk</span><span class="p">[</span><span class="n">j</span><span class="p">]);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="n">j</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="no">PL</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">L</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                </span><span class="k">break</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c1">// (Omitted: process last up-to L elements.)
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">out</span><span class="p">.</span><span class="n">extend_from_slice</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ans</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">out</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number">Code Snippet 27:</span>
In code, we interleave all layers by compiling a separate function for each height of the tree. Then the compiler can unroll the loop over the layers. There is a bunch of overhead in the code for the first and last iterations that's omitted.</div></details><figure class="inset large"><a href="/ox-hugo/8-interleave.svg"><img src="/ox-hugo/8-interleave.svg" alt="Figure 11: Interleaving all layers of the search binary search improves throughput from 29ns/query to 24ns/query."></a><figcaption><p><span class="figure-number">Figure 11: </span>Interleaving all layers of the search binary search improves throughput from <code>29ns/query</code> to <code>24ns/query</code>.</p></figcaption></figure><h1 id="optimizing-the-tree-layout"><span class="section-num">4</span> Optimizing the tree layout
<a class="heading-link" href="#optimizing-the-tree-layout"><i class="fa fa-link" aria-hidden="true"></i></a></h1><h2 id="left-tree"><span class="section-num">4.1</span> Left-tree
<a class="heading-link" href="#left-tree"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>So far, every internal node of the tree stores the minimum of the subtree on
it’s right (<a href="#figure--stree-full">Figure 3</a>, reproduced below).</p><figure class="inset large"><a href="/ox-hugo/full.svg"><img src="/ox-hugo/full.svg" alt="Figure 12: Usually in B+ trees, each node stores the minimum of it’s right subtree. Let’s call this a right (S+/B+) tree."></a><figcaption><p><span class="figure-number">Figure 12: </span>Usually in B+ trees, each node stores the minimum of it’s right subtree. Let’s call this a <em>right</em> (S+/B+) tree.</p></figcaption></figure><p>This turns out somewhat inefficient when searching values that are exactly in
between two subtrees (as <em>also</em> already suggested by Algorithmica), such as
<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="62" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>5.5</mn></math></mjx-assistive-mml></mjx-container>. In that case, the search descends into the
leftmost (green) subtree with node <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="63" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c5B"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="2"><mjx-c class="mjx-c34"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c5D"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>2</mn><mo>,</mo><mn>4</mn><mo stretchy="false">]</mo></math></mjx-assistive-mml></mjx-container>. Then, it goes to the rightmost
(red) node <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="64" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c5B"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="2"><mjx-c class="mjx-c35"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c5D"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>4</mn><mo>,</mo><mn>5</mn><mo stretchy="false">]</mo></math></mjx-assistive-mml></mjx-container>. There, we realize <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="65" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>5.5</mn><mo>&gt;</mo><mn>5</mn></math></mjx-assistive-mml></mjx-container>, and thus we need the next value
in the red layer (which is stored as a single array), which is <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="66" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>6</mn></math></mjx-assistive-mml></mjx-container>. The problem
now is that the red tree nodes exactly correspond to cache lines, and thus, the
<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="67" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>6</mn></math></mjx-assistive-mml></mjx-container> will be in a new cache line that needs to be fetched from memory.</p><p>Now consider the <em>left-max</em> tree below:</p><p><a id="figure--flipped"></a></p><figure class="inset large"><a href="/ox-hugo/flipped.svg"><img src="/ox-hugo/flipped.svg" alt="Figure 13: In the left-max S+ tree, each internal node contains the maximum of its left subtree."></a><figcaption><p><span class="figure-number">Figure 13: </span>In the <em>left-max</em> S+ tree, each internal node contains the maximum of its <em>left</em> subtree.</p></figcaption></figure><p>Now if we search for <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="68" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>5.5</mn></math></mjx-assistive-mml></mjx-container>, we descend into the middle subtree rooted at
<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="69" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c5B"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c37"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="2"><mjx-c class="mjx-c39"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c5D"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>7</mn><mo>,</mo><mn>9</mn><mo stretchy="false">]</mo></math></mjx-assistive-mml></mjx-container>. Then we go left to the <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="70" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c5B"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c36"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="2"><mjx-c class="mjx-c37"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c5D"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>6</mn><mo>,</mo><mn>7</mn><mo stretchy="false">]</mo></math></mjx-assistive-mml></mjx-container> node, and end up reading <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="71" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>6</mn></math></mjx-assistive-mml></mjx-container> as the
first value <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="72" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2265"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>≥</mo><mn>5.5</mn></math></mjx-assistive-mml></mjx-container>. Now, the search directly steers toward the node
that actually contains the answer, instead of the one just before.</p><figure class="inset large"><a href="/ox-hugo/9-left-max-tree.svg"><img src="/ox-hugo/9-left-max-tree.svg" alt="Figure 14: The left-S tree brings runtime down from 24ns/query for the interleaved version to 22ns/query now."></a><figcaption><p><span class="figure-number">Figure 14: </span>The left-S tree brings runtime down from <code>24ns/query</code> for the interleaved version to <code>22ns/query</code> now.</p></figcaption></figure><h2 id="memory-layouts"><span class="section-num">4.2</span> Memory layouts
<a class="heading-link" href="#memory-layouts"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>Let’s now consider some alternative memory layouts.
So far, we were packing all layers in forward order, but the Algorithmica post
actually stores them in reverse, so we’ll try that too. The query code is
exactly the same, since the order of the layers is already encoded into the offsets.</p><p>Another potential improvement is to always store a <em>full</em> array. This may seem
very inefficient, but is actually not that bad when we make sure to use
uninitialized memory. In that case, untouched memory pages will simply never be
mapped, so that we waste on average only about 2MB
per layer when hugepages are enabled, and 14MB when there are 7 layers and the
entire array takes 1GB.</p><p><a id="figure--layouts"></a></p><figure class="inset large"><a href="/ox-hugo/layouts.svg"><img src="/ox-hugo/layouts.svg" alt="Figure 15: So far we have been using the packed layout. We now also try the reversed layout as used by Algorithmica, and the full layout that allows simple arithmetic for indexing."></a><figcaption><p><span class="figure-number">Figure 15: </span>So far we have been using the packed layout. We now also try the <em>reversed</em> layout as used by Algorithmica, and the <em>full</em> layout that allows simple arithmetic for indexing.</p></figcaption></figure><p>A benefit of storing the full array is that instead of using the offsets, we can
simply compute the index in the next layer directly, as we did for the
Eytzinger search.</p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="cl"> pub fn batch_ptr3_full&lt;const P: usize&gt;(&amp;self, qb: &amp;[u32; P]) -&gt; [u32; P] {
</span></span><span class="line"><span class="cl">     let mut k = [0; P];
</span></span><span class="line"><span class="cl">     let q_simd = qb.map(|q| Simd::&lt;u32, 8&gt;::splat(q));
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="gi">+    let o = self.tree.as_ptr();
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>
</span></span><span class="line"><span class="cl"><span class="gd">-    for [o, o2] in offsets.array_windows() {
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+    for _l      in 0..self.offsets.len() - 1 {
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>         for i in 0..P {
</span></span><span class="line"><span class="cl">             let jump_to = unsafe { *o.byte_add(k[i]) }.find_splat64(q_simd[i]);
</span></span><span class="line"><span class="cl"><span class="gd">-            k[i] = k[i] * (B + 1) + jump_to     ;
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+            k[i] = k[i] * (B + 1) + jump_to + 64;
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>             prefetch_ptr(unsafe { o.byte_add(k[i]) });
</span></span><span class="line"><span class="cl">         }
</span></span><span class="line"><span class="cl">     }
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     from_fn(|i| {
</span></span><span class="line"><span class="cl">         let idx = unsafe { *o.byte_add(k[i]) }.find_splat(q_simd[i]);
</span></span><span class="line"><span class="cl">         unsafe { (o.byte_add(k[i]) as *const u32).add(idx).read() }
</span></span><span class="line"><span class="cl">     })
</span></span><span class="line"><span class="cl"> }
</span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number">Code Snippet 28:</span>
When storing the array in full, we can drop the per-layer offsets and instead compute indices directly.</div><figure class="inset large"><a href="/ox-hugo/9-params.svg"><img src="/ox-hugo/9-params.svg" alt="Figure 16: Comparison with reverse and full memory layout, and full memory layout with using a dedicated _full search that computes indices directly."></a><figcaption><p><span class="figure-number">Figure 16: </span>Comparison with reverse and full memory layout, and full memory layout with using a dedicated <code>_full</code> search that computes indices directly.</p></figcaption></figure><p>As it turns out, neither of those layouts improves performance, and so we will
not use them going forward.</p><h2 id="node-size-b-15"><span class="section-num">4.3</span> Node size <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="73" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi><mo>=</mo><mn>15</mn></math></mjx-assistive-mml></mjx-container>
<a class="heading-link" href="#node-size-b-15"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>We can also try storing only 15 values per node, so that the branching factor
is 16. This has the benefit of making the multiplication by <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="74" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi><mo>+</mo><mn>1</mn></math></mjx-assistive-mml></mjx-container> (17 so far)
slightly simpler, since it replaces <code>x = (x&lt;&lt;4)+x</code> by <code>x = x&lt;&lt;4</code>.</p><p><a id="figure--b15"></a></p><figure class="inset large"><a href="/ox-hugo/10-base15.svg"><img src="/ox-hugo/10-base15.svg" alt="Figure 17: Storing 15 values per node. The lines in the bottom part of the plot show the overhead that each data structure has relative to the size of the input, capped at 1 (which corresponds to take double the size)."></a><figcaption><p><span class="figure-number">Figure 17: </span>Storing 15 values per node. The lines in the bottom part of the plot show the overhead that each data structure has relative to the size of the input, capped at 1 (which corresponds to take double the size).</p></figcaption></figure><p>When the tree has up to 5 layers and the data fits in L3 cache, using <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="75" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi><mo>=</mo><mn>15</mn></math></mjx-assistive-mml></mjx-container> is
indeed slightly faster when the number of layers in the tree is the same. On the
other hand, the lower branching factor of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="76" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>16</mn></math></mjx-assistive-mml></mjx-container> requires an additional layer for smaller sizes than
when using branching factor <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="77" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c37"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>17</mn></math></mjx-assistive-mml></mjx-container>. When the input is much larger than L3 cache
the speedup disappears, because RAM throughput becomes a common bottleneck.</p><h3 id="data-structure-size"><span class="section-num">4.3.1</span> Data structure size
<a class="heading-link" href="#data-structure-size"><i class="fa fa-link" aria-hidden="true"></i></a></h3><p>Plain binary search and the Eytzinger layout have pretty much no overhead.
Our S+ tree so far has around <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="78" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c36"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mn>16</mn><mo>=</mo><mn>6.25</mn><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> overhead: <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="79" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c37"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mn>17</mn></math></mjx-assistive-mml></mjx-container> of the
values in the final layer is duplicated in the layer above, and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="80" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c37"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mn>17</mn></math></mjx-assistive-mml></mjx-container> of
<em>those</em> is duplicated again, and so on, for a total of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="81" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c37"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-msup><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c37"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.403em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22EF"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mn>17</mn><mo>+</mo><mn>1</mn><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><msup><mn>17</mn><mn>2</mn></msup><mo>+</mo><mo>⋯</mo><mo>=</mo><mn>1</mn><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mn>16</mn></math></mjx-assistive-mml></mjx-container>.</p><p>Using node size <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="82" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>15</mn></math></mjx-assistive-mml></mjx-container> instead, increases the overhead:
Each node now only stores <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="83" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>15</mn></math></mjx-assistive-mml></mjx-container> instead of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="84" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>16</mn></math></mjx-assistive-mml></mjx-container> elements, so that we already have
an overhead of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="85" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mn>15</mn></math></mjx-assistive-mml></mjx-container>. Furthermore the reduced branching factor increases the
duplication overhead fro <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="86" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mn>16</mn></math></mjx-assistive-mml></mjx-container> to <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="87" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mn>15</mn></math></mjx-assistive-mml></mjx-container> as well, for a total overhead of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="88" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c33"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c33"></mjx-c></mjx-mn><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>2</mn><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mn>15</mn><mo>=</mo><mn>13.3</mn><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container>, which matches the dashed blue line in <a href="#figure--b15">Figure 17</a>.</p><h2 id="summary"><span class="section-num">4.4</span> Summary
<a class="heading-link" href="#summary"><i class="fa fa-link" aria-hidden="true"></i></a></h2><figure class="inset large"><a href="/ox-hugo/11-summary.svg"><img src="/ox-hugo/11-summary.svg" alt="Figure 18: A summary of all the improvements we made so far."></a><figcaption><p><span class="figure-number">Figure 18: </span>A summary of all the improvements we made so far.</p></figcaption></figure><p>Of all the improvements so far, only the interleaving is maybe a bit too much:
it is the only method that does not work batch-by-batch, but really benefits
from having the full input at once. And also its code is three times longer
than the plain batched query methods because the first and last few
iterations of each loop are handled separately.</p><h1 id="prefix-partitioning"><span class="section-num">5</span> Prefix partitioning
<a class="heading-link" href="#prefix-partitioning"><i class="fa fa-link" aria-hidden="true"></i></a></h1><p>So far, we’ve been doing a purely <em>comparison-based search</em>.
Now, it is time for something new: <em>partitioning</em> the input values.</p><p>The simplest form of the idea is to simply partition values by their top <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="89" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>b</mi></math></mjx-assistive-mml></mjx-container>
bits, into <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="90" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.363em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mi>b</mi></msup></math></mjx-assistive-mml></mjx-container> parts. Then we can build <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="91" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.363em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mi>b</mi></msup></math></mjx-assistive-mml></mjx-container> independent search trees and
search each query in one of them. If <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="92" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>b</mi><mo>=</mo><mn>12</mn></math></mjx-assistive-mml></mjx-container>, this saves the first two levels of
the search (or slightly less, actually, since <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="93" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.393em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c33"></mjx-c></mjx-mn></mjx-script></mjx-msup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3C"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c37"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.403em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c33"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mrow data-mjx-texclass="ORD"><mn>12</mn></mrow></msup><mo>=</mo><msup><mn>16</mn><mn>3</mn></msup><mo>&lt;</mo><msup><mn>17</mn><mn>3</mn></msup></math></mjx-assistive-mml></mjx-container>).</p><h2 id="full-layout"><span class="section-num">5.1</span> Full layout
<a class="heading-link" href="#full-layout"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>In memory, we can store these trees very similar to the <em>full</em> layout we had
before, with the main differences that the first few layers are skipped and that
now there will be padding at the end of each part, rather than once at the end.</p><p><a id="figure--prefix"></a></p><figure class="inset large"><a href="/ox-hugo/prefix.svg"><img src="/ox-hugo/prefix.svg" alt="Figure 19: The full partitioned layout concatenates the full trees for all parts ‘horizontally’. As a new detail, when a part is not full, the smallest value of the next part is appended in the leaf layer."></a><figcaption><p><span class="figure-number">Figure 19: </span>The <em>full</em> partitioned layout concatenates the full trees for all parts ‘horizontally’. As a new detail, when a part is not full, the smallest value of the next part is appended in the leaf layer.</p></figcaption></figure><p>For some choices of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="94" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>b</mi></math></mjx-assistive-mml></mjx-container>, it could happen that up to <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="95" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>15</mn><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mn>16</mn></math></mjx-assistive-mml></mjx-container> of each tree is
padding. To reduce this overhead, we attempt to shrink <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="96" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>b</mi></math></mjx-assistive-mml></mjx-container> while keeping the
height of all trees the same: as long as all pairs of adjacent trees would
fit together in the same space, we decrease <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="97" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>b</mi></math></mjx-assistive-mml></mjx-container> by one. This way, all parts will
be filled for at least <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="98" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>50</mn><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> when the elements are evenly distributed.</p><p>Once construction is done, the code for querying is very similar to before: we
only have to start the search for each query at the index of its part, given by
<code>q &gt;&gt; shift</code> for some value of <code>shift</code>, rather than at index <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="99" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>0</mn></math></mjx-assistive-mml></mjx-container>.</p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="cl"> pub fn search_prefix&lt;const P: usize&gt;(&amp;self, qb: &amp;[u32; P]) -&gt; [u32; P] {
</span></span><span class="line"><span class="cl">     let offsets = self
</span></span><span class="line"><span class="cl">         .offsets
</span></span><span class="line"><span class="cl">         .iter()
</span></span><span class="line"><span class="cl">         .map(|o| unsafe { self.tree.as_ptr().add(*o) })
</span></span><span class="line"><span class="cl">         .collect_vec();
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     // Initial parts, and prefetch them.
</span></span><span class="line"><span class="cl">     let o0 = offsets[0];
</span></span><span class="line"><span class="cl"><span class="gd">-    let mut k = [0; P];
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+    let mut k = qb.map(|q| {
</span></span></span><span class="line"><span class="cl"><span class="gi">+        (q as usize &gt;&gt; self.shift) * 64
</span></span></span><span class="line"><span class="cl"><span class="gi">+    });
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>     let q_simd = qb.map(|q| Simd::&lt;u32, 8&gt;::splat(q));
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     for [o, o2] in offsets.array_windows() {
</span></span><span class="line"><span class="cl">         for i in 0..P {
</span></span><span class="line"><span class="cl">             let jump_to = unsafe { *o.byte_add(k[i]) }.find_splat64(q_simd[i]);
</span></span><span class="line"><span class="cl">             k[i] = k[i] * (B + 1) + jump_to;
</span></span><span class="line"><span class="cl">             prefetch_ptr(unsafe { o2.byte_add(k[i]) });
</span></span><span class="line"><span class="cl">         }
</span></span><span class="line"><span class="cl">     }
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     let o = offsets.last().unwrap();
</span></span><span class="line"><span class="cl">     from_fn(|i| {
</span></span><span class="line"><span class="cl">         let idx = unsafe { *o.byte_add(k[i]) }.find_splat(q_simd[i]);
</span></span><span class="line"><span class="cl">         unsafe { (o.byte_add(k[i]) as *const u32).add(idx).read() }
</span></span><span class="line"><span class="cl">     })
</span></span><span class="line"><span class="cl"> }
</span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number">Code Snippet 29:</span>
Searching the full layout of the partitioned tree starts in the partition in which each query belongs.</div><figure class="inset large"><a href="/ox-hugo/20-prefix.svg"><img src="/ox-hugo/20-prefix.svg" alt="Figure 20: The ‘simple’ partitioned tree, for (b_{textrm{max}}in {4,8,12,16,20}), shown as dotted lines."></a><figcaption><p><span class="figure-number">Figure 20: </span>The ‘simple’ partitioned tree, for (b_{textrm{max}}in {4,8,12,16,20}), shown as dotted lines.</p></figcaption></figure><p>We see that indeed, the partitioned tree has a space overhead varying between
<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="100" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>0</mn></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="101" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn></math></mjx-assistive-mml></mjx-container>, making this not yet useful in practice.
Larger <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="102" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>b</mi></math></mjx-assistive-mml></mjx-container> reduce the height of the remaining trees, and indeed we
see that queries are faster for larger <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="103" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>b</mi></math></mjx-assistive-mml></mjx-container>. Especially for small trees there is
a significant speedup over interleaving. Somewhat surprisingly, none of the
partition sizes has faster queries than interleaving for large inputs. Also
important to note is that while partitioning is very fast for sizes up to L1
cache, this is only possible because they have <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="104" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c226B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>≫</mo><mn>1</mn></math></mjx-assistive-mml></mjx-container> space overhead.</p><h2 id="compact-subtrees"><span class="section-num">5.2</span> Compact subtrees
<a class="heading-link" href="#compact-subtrees"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>Just like we used the <em>packed</em> layout before, we can also do that now, by simply
concatenating the representation of all packed subtrees.
We ensure that all subtrees are still padded into the same total size, but now
we only add as much padding as needed for the largest part, rather than padding
to <em>full</em> trees. Then, we give each tree the same layout in memory.</p><p>We’ll have offsets <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="105" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45C TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>o</mi><mi>ℓ</mi></msub></math></mjx-assistive-mml></mjx-container> of where each layer starts in the first tree, and we
store the constant size of the trees. That way, we can easily index each layer
of each part.</p><p><a id="figure--compact"></a></p><figure class="inset large"><a href="/ox-hugo/prefix-compact.svg"><img src="/ox-hugo/prefix-compact.svg" alt="Figure 21: Compared to before, Figure 19, the lowest level of each subtree now only takes 2 instead of 3 nodes."></a><figcaption><p><span class="figure-number">Figure 21: </span>Compared to before, <a href="#figure--prefix">Figure 19</a>, the lowest level of each subtree now only takes 2 instead of 3 nodes.</p></figcaption></figure><p>The code for querying does become slightly more complicated. Now, we must
explicitly track the part that each query belongs to, and compute all indices
based on the layer offset, the in-layer offset <code>k[i]</code>, <em>and</em> the part offset.</p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="cl"> pub fn search&lt;const P: usize&gt;(&amp;self, qb: &amp;[u32; P]) -&gt; [u32; P] {
</span></span><span class="line"><span class="cl">     let offsets = self
</span></span><span class="line"><span class="cl">         .offsets
</span></span><span class="line"><span class="cl">         .iter()
</span></span><span class="line"><span class="cl">         .map(|o| unsafe { self.tree.as_ptr().add(*o) })
</span></span><span class="line"><span class="cl">         .collect_vec();
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     // Initial parts, and prefetch them.
</span></span><span class="line"><span class="cl">     let o0 = offsets[0];
</span></span><span class="line"><span class="cl"><span class="gi">+    let mut k: [usize; P] = [0; P];
</span></span></span><span class="line"><span class="cl"><span class="gi">+    let parts: [usize; P] = qb.map(|q| {
</span></span></span><span class="line"><span class="cl"><span class="gi">+        // byte offset of the part.
</span></span></span><span class="line"><span class="cl"><span class="gi">+        (q as usize &gt;&gt; self.shift) * self.bpp * 64
</span></span></span><span class="line"><span class="cl"><span class="gi">+    });
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>     let q_simd = qb.map(|q| Simd::&lt;u32, 8&gt;::splat(q));
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     for [o, o2] in offsets.array_windows() {
</span></span><span class="line"><span class="cl">         for i in 0..P {
</span></span><span class="line"><span class="cl"><span class="gd">-            let jump_to = unsafe { *o.byte_add(           k[i]) }.find_splat64(q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+            let jump_to = unsafe { *o.byte_add(parts[i] + k[i]) }.find_splat64(q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>             k[i] = k[i] * (B + 1) + jump_to;
</span></span><span class="line"><span class="cl"><span class="gd">-            prefetch_ptr(unsafe { o2.byte_add(           k[i]) });
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+            prefetch_ptr(unsafe { o2.byte_add(parts[i] + k[i]) });
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>         }
</span></span><span class="line"><span class="cl">     }
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     let o = offsets.last().unwrap();
</span></span><span class="line"><span class="cl">     from_fn(|i| {
</span></span><span class="line"><span class="cl"><span class="gd">-        let idx = unsafe { *o.byte_add(           k[i]) }.find_splat(q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+        let idx = unsafe { *o.byte_add(parts[i] + k[i]) }.find_splat(q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gi"></span><span class="gd">-        unsafe { (o.byte_add(           k[i]) as *const u32).add(idx).read() }
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+        unsafe { (o.byte_add(parts[i] + k[i]) as *const u32).add(idx).read() }
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>     })
</span></span><span class="line"><span class="cl"> }
</span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number">Code Snippet 30:</span>
The indexing for the packed subtrees requires explicitly tracking the part of each query. This slows things down a bit.</div><figure class="inset large"><a href="/ox-hugo/21-compact.svg"><img src="/ox-hugo/21-compact.svg" alt="Figure 22: Compared to the the simple/full layout before (dark blue dots for (b=16)), the compact layout (e.g. red dots for (b=16)) consistently uses less memory, but is slightly slower."></a><figcaption><p><span class="figure-number">Figure 22: </span>Compared to the the simple/full layout before (dark blue dots for (b=16)), the compact layout (e.g. red dots for (b=16)) consistently uses less memory, but is slightly slower.</p></figcaption></figure><p>For fixed <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="106" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c78"></mjx-c></mjx-mtext></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>b</mi><mrow data-mjx-texclass="ORD"><mtext>max</mtext></mrow></msub></math></mjx-assistive-mml></mjx-container>, memory overhead of the compact layout is small as
long as the input is sufficiently large and the trees have sufficiently many
layers. Thus, this tree could be practical.
Unfortunately though, querying them is slightly slower than before,
because we must explicitly track the part of each query.</p><h2 id="the-best-of-both-compact-first-level"><span class="section-num">5.3</span> The best of both: compact first level
<a class="heading-link" href="#the-best-of-both-compact-first-level"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>As we just saw, storing the trees one by one slows queries down, so we would
like to avoid that. But on the other hand, the full layout can waste space.</p><p>Here, we combine the two ideas. We would like to store the <em>horizontal</em>
concatenation of the packed trees (each packed to the same size), but this is
complicated, because then levels would have a non-constant branching factor.
Instead, we can fully omit the last few (level 2) subtrees from each
tree, and pad those subtrees that <em>are</em> present to full subtrees.
This way, only the first level has a configurable branching factor <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="107" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>B</mi><mn>1</mn></msub></math></mjx-assistive-mml></mjx-container>, which we can
simply store after construction is done.</p><p>This layout takes slightly more space than before because the subtrees must
be full, but the overhead should typically be on the order of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="108" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mn>16</mn></math></mjx-assistive-mml></mjx-container>,
since (for uniform data) each tree will have <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="109" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2265"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c39"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>≥</mo><mn>9</mn></math></mjx-assistive-mml></mjx-container> subtrees, of which only
the last is not full.</p><p><a id="figure--l1"></a></p><figure class="inset large"><a href="/ox-hugo/prefix-l1.svg"><img src="/ox-hugo/prefix-l1.svg" alt="Figure 23: We can also store the horizontal concatenation of all trees. Here, the number of subtrees can be fixed to be less than (B+1), and is (2) instead of (B+1=3). Although not shown, deeper layers must always be full and have a (B+1) branching factor."></a><figcaption><p><span class="figure-number">Figure 23: </span>We can also store the horizontal concatenation of all trees. Here, the number of subtrees can be fixed to be less than (B+1), and is (2) instead of (B+1=3). Although not shown, deeper layers must always be full and have a (B+1) branching factor.</p></figcaption></figure><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="cl"> pub fn search_b1&lt;const P: usize&gt;(&amp;self, qb: &amp;[u32; P]) -&gt; [u32; P] {
</span></span><span class="line"><span class="cl">     let offsets = self
</span></span><span class="line"><span class="cl">         .offsets
</span></span><span class="line"><span class="cl">         .iter()
</span></span><span class="line"><span class="cl">         .map(|o| unsafe { self.tree.as_ptr().add(*o) })
</span></span><span class="line"><span class="cl">         .collect_vec();
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     let o0 = offsets[0];
</span></span><span class="line"><span class="cl">     let mut k: [usize; P] = qb.map(|q| {
</span></span><span class="line"><span class="cl">          (q as usize &gt;&gt; self.shift) * 64
</span></span><span class="line"><span class="cl">     });
</span></span><span class="line"><span class="cl">     let q_simd = qb.map(|q| Simd::&lt;u32, 8&gt;::splat(q));
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="gd">-    for         [o, o2]  in offsets.array_windows()        {
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+    if let Some([o1, o2]) = offsets.array_windows().next() {
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>         for i in 0..P {
</span></span><span class="line"><span class="cl">             let jump_to = unsafe { *o.byte_add(k[i]) }.find_splat64(q_simd[i]);
</span></span><span class="line"><span class="cl"><span class="gd">-            k[i] = k[i] * (B + 1) + jump_to;
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+            k[i] = k[i] * self.b1 + jump_to;
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>             prefetch_ptr(unsafe { o2.byte_add(k[i]) });
</span></span><span class="line"><span class="cl">         }
</span></span><span class="line"><span class="cl">     }
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="gd">-    for [o, o2] in offsets     .array_windows() {
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+    for [o, o2] in offsets[1..].array_windows() {
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>         for i in 0..P {
</span></span><span class="line"><span class="cl">             let jump_to = unsafe { *o.byte_add(k[i]) }.find_splat64(q_simd[i]);
</span></span><span class="line"><span class="cl">             k[i] = k[i] * (B + 1) + jump_to;
</span></span><span class="line"><span class="cl">             prefetch_ptr(unsafe { o2.byte_add(k[i]) });
</span></span><span class="line"><span class="cl">         }
</span></span><span class="line"><span class="cl">     }
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     let o = offsets.last().unwrap();
</span></span><span class="line"><span class="cl">     from_fn(|i| {
</span></span><span class="line"><span class="cl">         let idx = unsafe { *o.byte_add(k[i]) }.find_splat(q_simd[i]);
</span></span><span class="line"><span class="cl">         unsafe { (o.byte_add(k[i]) as *const u32).add(idx).read() }
</span></span><span class="line"><span class="cl">     })
</span></span><span class="line"><span class="cl"> }
</span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number">Code Snippet 31:</span>
Now, the code is simple again, in that we don't need to explicitly track part indices. All that changes is that we handle the first iteration of the for loop separately, and use branching factor <code>self.b1</code> instead of <code>B+1</code> there.</div><figure class="inset large"><a href="/ox-hugo/22-l1.svg"><img src="/ox-hugo/22-l1.svg" alt="Figure 24: When compressing the first level, space usage is very similar to the compact layout before, and query speed is as fast as the full layout before."></a><figcaption><p><span class="figure-number">Figure 24: </span>When compressing the first level, space usage is very similar to the compact layout before, and query speed is as fast as the full layout before.</p></figcaption></figure><h2 id="overlapping-trees"><span class="section-num">5.4</span> Overlapping trees
<a class="heading-link" href="#overlapping-trees"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>A drawback of all the above methods is that memory usage is heavily influenced by the
largest part, since all parts must be at least as large. This is especially a
problem when the distribution of part sizes is very skewed.
We can avoid this by sharing storage between adjacent trees.
Let <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="110" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.032em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mi>p</mi></msub></math></mjx-assistive-mml></mjx-container> be the number of subtrees for each part <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="111" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi></math></mjx-assistive-mml></mjx-container>, and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="112" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.032em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45A TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44E TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-munder space="4" limits="false"><mjx-mo class="mjx-n"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c78"></mjx-c></mjx-mo><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-munder><mjx-msub space="2"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.032em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mrow data-mjx-texclass="ORD"><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><mo>=</mo><munder><mo data-mjx-texclass="OP" movablelimits="true">max</mo><mi>p</mi></munder><msub><mi>S</mi><mi>p</mi></msub></math></mjx-assistive-mml></mjx-container>.
Then, we can define the <em>overlap</em> <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="113" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2264"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2264"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>0</mn><mo>≤</mo><mi>v</mi><mo>≤</mo><mi>B</mi></math></mjx-assistive-mml></mjx-container>, and append only
<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="114" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msub space="4"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.032em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45A TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44E TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>B</mi><mn>1</mn></msub><mo>=</mo><msub><mi>S</mi><mrow data-mjx-texclass="ORD"><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><mo>−</mo><mi>v</mi></math></mjx-assistive-mml></mjx-container> new subtrees for each new part, rather than <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="115" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.032em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45A TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44E TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mrow data-mjx-texclass="ORD"><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> as we
did before.
The values for each part are then simply appended where the previous part left
off, unless that subtree is ‘out-of-reach’ for the current part, in which
case first some padding is added.
This way, consecutive
parts can overlap and exchange memory, and we can somewhat ‘buffer’ the effect
of large parts.</p><p><a id="figure--overlap"></a></p><figure class="inset large"><a href="/ox-hugo/prefix-overlapping.svg"><img src="/ox-hugo/prefix-overlapping.svg" alt="Figure 25: In this example, the third tree has (6) values in ([8, 12)) and requires (S_{max}=3) subtrees. We have an overlap of (v=1), so that for each additional tree, only (2) subtrees are added. We add padding elements in grey to ensure all elements are reachable from their own tree."></a><figcaption><p><span class="figure-number">Figure 25: </span>In this example, the third tree has (6) values in ([8, 12)) and requires (S_{max}=3) subtrees. We have an overlap of (v=1), so that for each additional tree, only (2) subtrees are added. We add padding elements in grey to ensure all elements are reachable from their own tree.</p></figcaption></figure><p>When the overlap is <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="116" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn></math></mjx-assistive-mml></mjx-container>, as in the example above, the nodes in the first layer
each contain the maximum value of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="117" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi></math></mjx-assistive-mml></mjx-container> subtrees. When the overlap is larger than
<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="118" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn></math></mjx-assistive-mml></mjx-container>, the nodes in the first layer would contain overlapping values. Instead, we
store a single list of values, in which we can do <em>unaligned</em> reads to get the
right slice of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="119" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi></math></mjx-assistive-mml></mjx-container> values that we need.</p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="cl"> pub fn search&lt;const P: usize, const PF: bool&gt;(&amp;self, qb: &amp;[u32; P]) -&gt; [u32; P] {
</span></span><span class="line"><span class="cl">     let offsets = self
</span></span><span class="line"><span class="cl">         .offsets
</span></span><span class="line"><span class="cl">         .iter()
</span></span><span class="line"><span class="cl">         .map(|o| unsafe { self.tree.as_ptr().add(*o) })
</span></span><span class="line"><span class="cl">         .collect_vec();
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     let o0 = offsets[0];
</span></span><span class="line"><span class="cl">     let mut k: [usize; P] = qb.map(|q| {
</span></span><span class="line"><span class="cl"><span class="gd">-        (q as usize &gt;&gt; self.shift) * 4 *  16
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+        (q as usize &gt;&gt; self.shift) * 4 * (16 - self.overlap)
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>     });
</span></span><span class="line"><span class="cl">     let q_simd = qb.map(|q| Simd::&lt;u32, 8&gt;::splat(q));
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     if let Some([o1, o2]) = offsets.array_windows().next() {
</span></span><span class="line"><span class="cl">         for i in 0..P {
</span></span><span class="line"><span class="cl"><span class="gi">+            // First level read may be unaligned.
</span></span></span><span class="line"><span class="cl"><span class="gi"></span><span class="gd">-            let jump_to = unsafe { *o.byte_add(k[i])                  }.find_splat64(q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+            let jump_to = unsafe {  o.byte_add(k[i]).read_unaligned() }.find_splat64(q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>             k[i] = k[i] * self.l1 + jump_to;
</span></span><span class="line"><span class="cl">             prefetch_ptr(unsafe { o2.byte_add(k[i]) });
</span></span><span class="line"><span class="cl">         }
</span></span><span class="line"><span class="cl">     }
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     for [o, o2] in offsets[1..].array_windows() {
</span></span><span class="line"><span class="cl">         for i in 0..P {
</span></span><span class="line"><span class="cl">             let jump_to = unsafe { *o.byte_add(k[i]) }.find_splat64(q_simd[i]);
</span></span><span class="line"><span class="cl">             k[i] = k[i] * (B + 1) + jump_to;
</span></span><span class="line"><span class="cl">             prefetch_ptr(unsafe { o2.byte_add(k[i]) });
</span></span><span class="line"><span class="cl">         }
</span></span><span class="line"><span class="cl">     }
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     let o = offsets.last().unwrap();
</span></span><span class="line"><span class="cl">     from_fn(|i| {
</span></span><span class="line"><span class="cl"><span class="gd">-        let idx = unsafe { *o.byte_add(k[i])                  }.find_splat(q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+        let idx = unsafe {  o.byte_add(k[i]).read_unaligned() }.find_splat(q_simd[i]);
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>         unsafe { (o.byte_add(k[i]) as *const u32).add(idx).read() }
</span></span><span class="line"><span class="cl">     })
</span></span><span class="line"><span class="cl"> }
</span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number">Code Snippet 32:</span>
Each part now contains <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="120" style="font-size: 119.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>16</mn><mo>−</mo><mi>v</mi></math></mjx-assistive-mml></mjx-container> values, instead of the original 16. We use <code>read_unaligned</code> since we do not always read at 16-value boundaries anymore.</div><figure class="inset large"><a href="/ox-hugo/23-overlap.svg"><img src="/ox-hugo/23-overlap.svg" alt="Figure 26: Overlapping trees usually use less memory than the equivalent version with first-level compression, while being about as fast."></a><figcaption><p><span class="figure-number">Figure 26: </span>Overlapping trees usually use less memory than the equivalent version with first-level compression, while being about as fast.</p></figcaption></figure><h2 id="human-data"><span class="section-num">5.5</span> Human data
<a class="heading-link" href="#human-data"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>So far we’ve been testing with uniform random data, where the largest part
deviates form the mean size by around <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="121" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msqrt><mjx-sqrt><mjx-surd><mjx-mo class="mjx-n"><mjx-c class="mjx-c221A"></mjx-c></mjx-mo></mjx-surd><mjx-box style="padding-top: 0.281em;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-box></mjx-sqrt></mjx-msqrt></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msqrt><mi>n</mi></msqrt></math></mjx-assistive-mml></mjx-container>. Now, let’s look at some real
data: k-mers of a human genome. DNA consists of <code>ACGT</code> characters that can be
encoded as 2 bits, so each string of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="122" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi><mo>=</mo><mn>16</mn></math></mjx-assistive-mml></mjx-container> characters defines a 32 bit
integer<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a><span class="fn-tooltip"><span class="fn-number">5</span><span class="fn-text"><p>We throw away the most significant bit to get 31 bit values.&nbsp;</p></span></span></sup>.
We then look at the first <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="123" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></mjx-assistive-mml></mjx-container> k-mers of the human genome, starting at chromosome 1.</p><p>To give an idea, the plot below show for each k-mer of length <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="124" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi><mo>=</mo><mn>12</mn></math></mjx-assistive-mml></mjx-container> how often
it occurs in the full human genome. In total, there are around 3G
k-mers, and so the expected count for each k-mer is around 200. But instead,
we see k-mers that occur over 2 million times! So if we were to partition on the
first 24 bits, the size of the largest part is only around <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="125" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mrow data-mjx-texclass="ORD"><mo>−</mo><mn>10</mn></mrow></msup></math></mjx-assistive-mml></mjx-container> of the input,
rather than <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="126" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mrow data-mjx-texclass="ORD"><mo>−</mo><mn>24</mn></mrow></msup></math></mjx-assistive-mml></mjx-container>.</p><p>The accumulated counts are shown in orange, where we also see a number of flat
regions caused by underrepresented k-mers.</p><figure class="inset"><a href="/ox-hugo/rank-curve.png"><img src="/ox-hugo/rank-curve.png" alt="Figure 27: A plot showing k-mer counts for all (4^{12} = 16M) $k=12$-mers of the human genome. On random data each k-mer would occur around 200 times, but here we see some k-mers occurring over 2 million times."></a><figcaption><p><span class="figure-number">Figure 27: </span>A plot showing k-mer counts for all (4^{12} = 16M) <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="127" style="font-size: 119.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi><mo>=</mo><mn>12</mn></math></mjx-assistive-mml></mjx-container>-mers of the human genome. On random data each k-mer would occur around 200 times, but here we see some k-mers occurring over 2 million times.</p></figcaption></figure><figure class="inset large"><a href="/ox-hugo/23-overlap-human.svg"><img src="/ox-hugo/23-overlap-human.svg" alt="Figure 28: Building the overlapping trees for k-mers of the human genome takes much more space, and even using only 16 parts regularly requires up to 50% overhead, making this data structure not quite practical."></a><figcaption><p><span class="figure-number">Figure 28: </span>Building the overlapping trees for k-mers of the human genome takes much more space, and even using only 16 parts regularly requires up to 50% overhead, making this data structure not quite practical.</p></figcaption></figure><h2 id="prefix-map"><span class="section-num">5.6</span> Prefix map
<a class="heading-link" href="#prefix-map"><i class="fa fa-link" aria-hidden="true"></i></a></h2><p>We need a way to handle unbalanced partition sizes, instead of mapping
everything linearly.
We can do this by simply storing the full tree compactly as we did before,
preceded by an array (in blue below) that points to the index of the first
subtree containing elements of the part. Like for the overlapping trees before,
the first layer is simply a list of the largest elements of all subtrees that
can be indexed anywhere (potentially unaligned).</p><figure class="inset large"><a href="/ox-hugo/prefix-map.svg"><img src="/ox-hugo/prefix-map.svg" alt="Figure 29: The prefix map, in blue, stores (2^b) elements, that for each $b$-bit prefix stores the index of the first subtree that contains an element of that prefix."></a><figcaption><p><span class="figure-number">Figure 29: </span>The prefix map, in blue, stores (2^b) elements, that for each <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="128" style="font-size: 119.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>b</mi></math></mjx-assistive-mml></mjx-container>-bit prefix stores the index of the first subtree that contains an element of that prefix.</p></figcaption></figure><p>To answer a query, we first find its part, then read the block (16 elements)
starting at the pointed-to element, and then proceed as usual from the sub-tree onward.</p><div class="highlight"><div class="chroma"><table class="lntable"><tbody><tr><td class="lntd"><pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span></code></pre></td><td class="lntd"><pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="cl"> pub fn search&lt;const P: usize, const PF: bool&gt;(&amp;self, qb: &amp;[u32; P]) -&gt; [u32; P] {
</span></span><span class="line"><span class="cl">     let offsets = self
</span></span><span class="line"><span class="cl">         .offsets
</span></span><span class="line"><span class="cl">         .iter()
</span></span><span class="line"><span class="cl">         .map(|o| unsafe { self.tree.as_ptr().add(*o) })
</span></span><span class="line"><span class="cl">         .collect_vec();
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     let o0 = offsets[0];
</span></span><span class="line"><span class="cl">     let mut k: [usize; P] = qb.map(|q| {
</span></span><span class="line"><span class="cl"><span class="gd">-                 4 * (16 - self.overlap)         * (q as usize &gt;&gt; self.shift)
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+        unsafe { 4 * *self.prefix_map.get_unchecked(q as usize &gt;&gt; self.shift) }
</span></span></span><span class="line"><span class="cl"><span class="gi"></span>     });
</span></span><span class="line"><span class="cl">     let q_simd = qb.map(|q| Simd::&lt;u32, 8&gt;::splat(q));
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     if let Some([o1, o2]) = offsets.array_windows().next() {
</span></span><span class="line"><span class="cl">         for i in 0..P {
</span></span><span class="line"><span class="cl">             let jump_to = unsafe {  o.byte_add(k[i]).read_unaligned() }.find_splat64(q_simd[i]);
</span></span><span class="line"><span class="cl">             k[i] = k[i] * self.l1 + jump_to;
</span></span><span class="line"><span class="cl">             prefetch_ptr(unsafe { o2.byte_add(k[i]) });
</span></span><span class="line"><span class="cl">         }
</span></span><span class="line"><span class="cl">     }
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     for [o, o2] in offsets[1..].array_windows() {
</span></span><span class="line"><span class="cl">         for i in 0..P {
</span></span><span class="line"><span class="cl">             let jump_to = unsafe { *o.byte_add(k[i]) }.find_splat64(q_simd[i]);
</span></span><span class="line"><span class="cl">             k[i] = k[i] * (B + 1) + jump_to;
</span></span><span class="line"><span class="cl">             prefetch_ptr(unsafe { o2.byte_add(k[i]) });
</span></span><span class="line"><span class="cl">         }
</span></span><span class="line"><span class="cl">     }
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     let o = offsets.last().unwrap();
</span></span><span class="line"><span class="cl">     from_fn(|i| {
</span></span><span class="line"><span class="cl">         let idx = unsafe {  o.byte_add(k[i]).read_unaligned() }.find_splat(q_simd[i]);
</span></span><span class="line"><span class="cl">         unsafe { (o.byte_add(k[i]) as *const u32).add(idx).read() }
</span></span><span class="line"><span class="cl">     })
</span></span><span class="line"><span class="cl"> }
</span></span></code></pre></td></tr></tbody></table></div></div><div class="src-block-caption"><span class="src-block-number">Code Snippet 33:</span>
In code, the only thing that changes compared to the previous overlapping version is that instead of computing the start index linearly (and adapting the element layout accordingly), we use the <code>prefix_map</code> to jump directly to the right place in the packed tree representation.</div><figure class="inset large"><a href="/ox-hugo/24-map.svg"><img src="/ox-hugo/24-map.svg" alt="Figure 30: As long as there are more elements than parts and the tree has at least two layers, the space overhead of this representation is close to (1/16) again."></a><figcaption><p><span class="figure-number">Figure 30: </span>As long as there are more elements than parts and the tree has at least two layers, the space overhead of this representation is close to (1/16) again.</p></figcaption></figure><p>Although memory usage is now similar to the unpartitioned version, queries for
large inputs are slightly slower than those previous layouts due to the
additional index required.</p><p>We can also again do the interleaving queries. These are slightly faster for
small inputs, and around as fast as interleaving was without the partitioning.</p><figure class="inset large"><a href="/ox-hugo/25-map-interleave.svg"><img src="/ox-hugo/25-map-interleave.svg" alt="Figure 31: Prefix-map index with interleaving queries on random data."></a><figcaption><p><span class="figure-number">Figure 31: </span>Prefix-map index with interleaving queries on random data.</p></figcaption></figure><p>On human data, we see that the partitioned index is a bit faster in L1 and L2,
and consistently saves the time of roughly one layer in L3. For larger indices,
performance is still very similar to not using partitioning at all.</p><figure class="inset large"><a href="/ox-hugo/25-map-interleave-human.svg"><img src="/ox-hugo/25-map-interleave-human.svg" alt="Figure 32: Prefix-map with interleaving on human data."></a><figcaption><p><span class="figure-number">Figure 32: </span>Prefix-map with interleaving on human data.</p></figcaption></figure><h2 id="prefix-summary"><span class="section-num">5.7</span> Summary
<a class="heading-link" href="#prefix-summary"><i class="fa fa-link" aria-hidden="true"></i></a></h2><figure class="inset large"><a href="/ox-hugo/27-summary.svg"><img src="/ox-hugo/27-summary.svg" alt="Figure 33: Summary of partitioning results. Overall, it seems that partitioning does not provide when we already interleave queries."></a><figcaption><p><span class="figure-number">Figure 33: </span>Summary of partitioning results. Overall, it seems that partitioning does not provide when we already interleave queries.</p></figcaption></figure><h1 id="multi-threaded-comparison"><span class="section-num">6</span> Multi-threaded comparison
<a class="heading-link" href="#multi-threaded-comparison"><i class="fa fa-link" aria-hidden="true"></i></a></h1><p><a id="figure--find-results"></a></p><figure class="inset large"><a href="/ox-hugo/28-threads.svg"><img src="/ox-hugo/28-threads.svg" alt="Figure 34: When using 6 threads, runtime goes down from 27ns to 7ns. Given that the speedup is less than 4x, we are now bottlenecked by total RAM throughput, and indeed methods that are slower for a single thread also reach near-optimal throughput now."></a><figcaption><p><span class="figure-number">Figure 34: </span>When using 6 threads, runtime goes down from <code>27ns</code> to <code>7ns</code>. Given that the speedup is less than 4x, we are now bottlenecked by total RAM throughput, and indeed methods that are slower for a single thread also reach near-optimal throughput now.</p></figcaption></figure><h1 id="conclusion"><span class="section-num">7</span> Conclusion
<a class="heading-link" href="#conclusion"><i class="fa fa-link" aria-hidden="true"></i></a></h1><p>All together, we went from <code>1150ns/query</code> for binary search on 4GB input to
<code>27ns</code> for the optimized S-tree with interleaved queries, over <code>40x</code> speedup!
A large part of this improvement is due to <strong>batching</strong> queries and <strong>prefetching</strong>
upcoming nodes. To get even higher throughput, <strong>interleaving</strong> queries at different
levels helps to balance the CPU-bound part of the computation with the
memory-bound part, so that we get a higher overall throughput. Using a <strong>15
elements per node</strong> instead of 16 also improves throughput somewhat, but doubles
the overhead of the data structure from 6.25% to 13.3%. For inputs that fit in
L3 cache that’s fine and the speedup is worthwhile, while for larger inputs the
speed is memory-bound anyway, so that there is no speedup while the additional
memory requirements are somewhat large.</p><p>We also looked into <strong>partitioning</strong> the data by prefix. While this does give some speedup,
it turns out that on skewed input data, the benefits quickly
diminish since the tree either requires a lot of buffer space, or else requires
an additional lookup to map each part to its location in the first level of the tree.
In the end, I’d say the additional complexity and dependency on the shape of
the input data of partitioning is not worth the speedup compared to simply using interleaved
queries directly.</p><h2 id="future-work"><span class="section-num">7.1</span> Future work
<a class="heading-link" href="#future-work"><i class="fa fa-link" aria-hidden="true"></i></a></h2><h3 id="branchy-search"><span class="section-num">7.1.1</span> Branchy search
<a class="heading-link" href="#branchy-search"><i class="fa fa-link" aria-hidden="true"></i></a></h3><p>All methods we considered are <em>branchless</em> and use the exact same number of
iterations for each query. Especially in combination with partitioning, it may
be possible to handle the few large parts independently from the usual
smaller parts. That way we could answer most queries with slightly fewer
iterations.</p><p>On the other hand, the layers saved would mostly be the quick lookups near the
root of the tree, and introducing branches to the code could possibly cause
quite a bit of delay due to mispredictions.</p><h3 id="interpolation-search"><span class="section-num">7.1.2</span> Interpolation search
<a class="heading-link" href="#interpolation-search"><i class="fa fa-link" aria-hidden="true"></i></a></h3><p>As we saw in the last plot above, total RAM throughput (rather than per-core
throughput) becomes a bottleneck once we’re using multiple threads.
Thus, the only way to improve total query throughput is to use strictly fewer RAM
accesses per query.
Prefix lookups won’t help, since they only replace the layers of the tree
that would otherwise fit in the cache. Instead, we could use <em>interpolation
search</em> (<a href="https://en.wikipedia.org/wiki/Interpolation_search">wikipedia</a>), where the estimated position of a query <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="129" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></mjx-assistive-mml></mjx-container> is linearly
interpolated between known positions of surrounding elements. On random data, this only takes
<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="130" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-n"><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c67"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-mi class="mjx-n" space="2"><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c67"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mi>lg</mi><mo data-mjx-texclass="NONE">⁡</mo><mi>lg</mi><mo data-mjx-texclass="NONE">⁡</mo><mi>n</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> iterations, rather than <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="131" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-n"><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c67"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mi>lg</mi><mo data-mjx-texclass="NONE">⁡</mo><mi>n</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> for binary search, and could
save some RAM accesses. On the
other hand, when data is not random its worst case performance is <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="132" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> rather
than the statically bounded <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="133" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-n"><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c67"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mi>lg</mi><mo data-mjx-texclass="NONE">⁡</mo><mi>n</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>.</p><p>The PLA-index (<a href="#citeproc_bib_item_1">Abrar and Medvedev 2024</a>) also uses a single interpolation step in a
precisely constructed piece wise linear approximation. The error after the
approximation is determined by some global upper bound, so that the number of remaining
search steps can be bounded as well.</p><h3 id="packing-data-smaller"><span class="section-num">7.1.3</span> Packing data smaller
<a class="heading-link" href="#packing-data-smaller"><i class="fa fa-link" aria-hidden="true"></i></a></h3><p>Another option to use the RAM lookups more efficiently would be to pack values
into 16 bits rather than the 32 bits we’ve been using so far. Especially if we
first do a 16 bit prefix lookup, we already know those bits anyway, so it would
suffice to only compare the last 16 bits of the query and values. This increases
the branching factor from 17 to 33, which reduces the number of layers of the
tree by around 1.5 for inputs of 1GB.</p><h3 id="returning-indices-in-original-data"><span class="section-num">7.1.4</span> Returning indices in original data
<a class="heading-link" href="#returning-indices-in-original-data"><i class="fa fa-link" aria-hidden="true"></i></a></h3><p>For various applications, it may be helpful to not only return the smallest
value <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="134" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2265"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>≥</mo><mi>q</mi></math></mjx-assistive-mml></mjx-container>, but also the index in the original list of sorted values, for
example when storing an array with additional data for each item.</p><p>Since we use the S+ tree that stores all data in the bottom layer, this is
mostly straightforward. The <em>prefix map</em> partitioned tree also natively supports
this, while the other partitioned variants do not: they include buffer/padding
elements in their bottom layer, and hence we would need to store and look up the position
offset of each part separately.</p><h3 id="range-queries"><span class="section-num">7.1.5</span> Range queries
<a class="heading-link" href="#range-queries"><i class="fa fa-link" aria-hidden="true"></i></a></h3><p>We could extend the current query methods to a version that return both the
first value <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="135" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2265"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>≥</mo><mi>q</mi></math></mjx-assistive-mml></mjx-container> and the first value <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="136" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&gt;</mo><mi>q</mi></math></mjx-assistive-mml></mjx-container>, so that the range of positions
corresponding to value <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="137" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></mjx-assistive-mml></mjx-container> can be determined. In practice, the easiest way to do
this is by simply doubling the queries into <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="138" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="139" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi><mo>+</mo><mn>1</mn></math></mjx-assistive-mml></mjx-container>. This will cause some
CPU overhead in the initial layers, but the query execution will remain
branch-free. When <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="140" style="font-size: 119.6%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></mjx-assistive-mml></mjx-container> is not found or only occurs a few times, they will mostly
fetch the same cache lines, so that memory is efficiently reused and the
bandwidth can be used for other queries.</p><p>In practice though, this seems only around 20% faster per individual query for 4GB input, so
around 60% slower for a range than for a single query. For small inputs, the
speedup is less, and sometimes querying ranges is even more than twice slower
than individual random queries.</p><h1 id="references">References
<a class="heading-link" href="#references"><i class="fa fa-link" aria-hidden="true"></i></a></h1><style>.csl-entry{text-indent:-1.5em;margin-left:1.5em}</style><div class="csl-bib-body"><div class="csl-entry"><a id="citeproc_bib_item_1"></a>Abrar, Md. Hasin, and Paul Medvedev. 2024. “Pla-Index: A K-Mer Index Exploiting Rank Curve Linearity.” Schloss Dagstuhl – Leibniz-Zentrum für Informatik. <a href="https://doi.org/10.4230/LIPICS.WABI.2024.13">https://doi.org/10.4230/LIPICS.WABI.2024.13</a>.</div><div class="csl-entry"><a id="citeproc_bib_item_2"></a>Khuong, Paul-Virak, and Pat Morin. 2017. “Array Layouts for Comparison-Based Searching.” <i>Acm Journal of Experimental Algorithmics</i> 22 (May): 1–39. <a href="https://doi.org/10.1145/3053370">https://doi.org/10.1145/3053370</a>.</div></div><div class="footnotes" role="doc-endnotes"><hr><ol><li id="fn:1"><p>You’ll see later why not 32bit&nbsp;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">↩︎</a></p></li><li id="fn:2"><p>One might argue that this is unrealistic since
in practice processors <em>do</em> have dynamic frequencies, but here I prefer reproducible
benchmarks over realistic benchmarks.&nbsp;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">↩︎</a></p></li><li id="fn:3"><p>;)&nbsp;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">↩︎</a></p></li><li id="fn:4"><p>It would be really cool if we could teach compilers this trick. It already
auto-vectorized the counting code anyway, so this is not that much more work I’d
say.&nbsp;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">↩︎</a></p></li><li id="fn:5"><p>We throw away the most significant bit to get 31 bit values.&nbsp;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">↩︎</a></p></li></ol></div></div><footer><div class="utterances">
    <iframe class="utterances-frame" title="Comments" scrolling="no" src="https://utteranc.es/utterances.html?src=https%3A%2F%2Futteranc.es%2Fclient.js&amp;repo=ragnargrootkoerkamp%2Fresearch&amp;issue-term=pathname&amp;label=comments&amp;theme=github-dark&amp;crossorigin=anonymous&amp;async=&amp;url=https%3A%2F%2Fcuriouscoding.nl%2Fposts%2Fstatic-search-tree%2F&amp;origin=https%3A%2F%2Fcuriouscoding.nl&amp;pathname=posts%2Fstatic-search-tree%2F&amp;title=Static+search+trees%3A+40x+faster+than+binary+search+%C2%B7+CuriousCoding&amp;description=%0ATable+of+Contents%0A%0A1+Introduction%0A%0A1.1+Problem+statement%0A1.2+Recommended+reading%0A1.3+Binary+search+and+Eytzinger+layout%0A1.4+Hugepages%0A1.5+A+note+on+benchmarking%0A1.6+Cache+lines%0A1.7+S-trees+and+B-trees%0A%0A%0A2+Optimizing+find%0A%0A2.1+Linear%0A2.2+Auto-vectorization%0A2.3+Trailing+zeros%0A2.4+Popcount%0A2.5+Manual+SIMD%0A%0A%0A3+Optimizing+the+search%0A%0A3.1+Batching%0A3.2+Prefetching%0A3.3+Pointer+arithmetic%0A%0A3.3.1+Up-front+splat%0A3.3.2+Byte-based+pointers%0A3.3.3+The+final+version%0A%0A%0A3.4+Skip+prefetch%0A3.5+Interleave%0A%0A%0A4+Optimizing+the+tree+layout%0A%0A4.1+Left-tree%0A4.2+Memory+layouts%0A4.3+Node+size+%5C%28B%3D15%5C%29%0A%0A4.3.1+Data+structure+size%0A%0A%0A4.4+Summary%0A%0A%0A5+Prefix+partitioning%0A%0A5.1+Full+layout%0A5.2+Compact+subtrees%0A5.3+The+best+of+both%3A+compact+first+l&amp;og%3Atitle=Static+search+trees%3A+40x+faster+than+binary+search&amp;session=" loading="lazy"></iframe>
  </div></footer></article><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],processEscapes:!0,processEnvironments:!0,tags:"ams"},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script></section></div><footer class="footer"><section class="container"><div class="links"><a href="https://github.com/RagnarGrootKoerkamp/" aria-label="Github">GitHub <i class="fa fa-github fa-1x" aria-hidden="true"></i></a>
·
<a href="https://twitter.com/curious_coding/" aria-label="Twitter">Twitter <i class="fa fa-twitter fa-1x" aria-hidden="true"></i></a>
·
<a href="https://scholar.google.ch/citations?hl=en&amp;user=yM9CokEAAAAJ" aria-label="Google Scholar">Google Scholar <i class="fa google-scholar fa-1x" aria-hidden="true"></i></a>
·
<a href="https://www.biorxiv.org/search/author1%3ARagnar%2BGroot%2BKoerkamp" aria-label="bioRxiv">bioRxiv</a>
·
<a href="https://arxiv.org/search/?query=Ragnar+Groot+Koerkamp&amp;searchtype=author" aria-label="Arxiv">Arxiv</a>
·
<a href="https://orcid.org/0000-0002-2091-1237" aria-label="ORCID">ORCID</a>
·
<a href="index.xml" aria-label="RSS">RSS <i class="fa fa-rss fa-1x" aria-hidden="true"></i></a></div><p>This blog is <a href="https://github.com/RagnarGrootKoerkamp/research">open source</a> and licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>.</p>©
2021 -
2024
Ragnar {Groot Koerkamp}
·
Powered by <a href="https://gohugo.io/">Hugo</a> &amp; <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.</section></footer></main><script src="/js/coder.min.cb0c595e02234420f3ad3886bf4a9bd2874d0e1e78e090138a9ef158b35aaf17.js" integrity="sha256-ywxZXgIjRCDzrTiGv0qb0odNDh544JATip7xWLNarxc="></script><script src="/js/toc.js"></script><script src="/js/footnote.js"></script><script src="/js/code.js"></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-VC3594H2Q8"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-VC3594H2Q8")</script></body></html>